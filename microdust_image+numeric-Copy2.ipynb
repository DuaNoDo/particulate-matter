{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from PIL import Image\n",
    "from imutils import paths\n",
    "from os import path\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "import pandas as pd\n",
    "keras.__version__\n",
    "IMAGE_DIMS = (350,250,3)\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_arr = np.load('./new_date_arr.npy',allow_pickle=True)\n",
    "dust_arr = np.load('./result_arr_avg_7.npy',allow_pickle=True)\n",
    "wind_arr = np.load('./wind_arr.npy',allow_pickle=True)\n",
    "humi_arr = np.load('./humi_arr.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 18126 images (22940.04MB)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time() \n",
    "imagePaths = sorted(list(paths.list_images('./dataset/image')))\n",
    "image_arr = []\n",
    "\n",
    "for i in imagePaths:\n",
    "    img_name = int(path.splitext(path.basename(i))[0])\n",
    "    \n",
    "    if img_name in date_arr :\n",
    "        image = Image.open(i)\n",
    "        image = image.resize((IMAGE_DIMS[0],IMAGE_DIMS[1]))\n",
    "        image = img_to_array(image)\n",
    "        image_arr.append(image)\n",
    "        \n",
    "image_arr = np.array(image_arr, dtype=\"float\") / 255.0        \n",
    "print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(len(imagePaths), image_arr.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11186,)\n",
      "(11186, 250, 350, 3)\n",
      "(8948, 250, 350, 3)\n",
      "(2238, 250, 350, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "con_data_img = image_arr\n",
    "con_data_val = dust_arr\n",
    "\n",
    "print(wind_arr.shape)\n",
    "con_data_wea = np.concatenate([wind_arr.reshape(len(wind_arr),1),humi_arr.reshape(len(humi_arr),1)], axis=1)\n",
    "\n",
    "\n",
    "# 국내는 PM2.5이 16이상이면 보통\n",
    "# for i in range(0,dustvalue.shape[0]):\n",
    "#     if int(dustvalue[i]) > 0 :\n",
    "#         con_data_img.append(data[i])\n",
    "#         con_data_val.append(dustvalue[i])\n",
    "#         con_data_wea.append(add_info[i])\n",
    "        \n",
    "# con_data_img, con_data_val, con_data_wea = shuffle(np.array(con_data_img), np.array(con_data_val), np.array(con_data_wea), random_state=0)\n",
    "# con_data_img = np.array(con_data_img)\n",
    "# con_data_val = np.array(con_data_val)\n",
    "# con_data_wea = np.array(con_data_wea)\n",
    "\n",
    "num = int(con_data_img.shape[0]*0.8)\n",
    "\n",
    "train_img = con_data_img[:num]\n",
    "train_val = con_data_val[:num]\n",
    "train_wea = con_data_wea[:num]\n",
    "\n",
    "test_img = con_data_img[num:]\n",
    "test_val = con_data_val[num:]\n",
    "test_wea = con_data_wea[num:]\n",
    "\n",
    "print(con_data_img.shape)\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, LSTM, GRU, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "chanDim=-1\n",
    "model = Sequential()\n",
    "\n",
    "# CONV => RELU => POOL\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(IMAGE_DIMS[1], IMAGE_DIMS[0],3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "image_input = Input(shape=(IMAGE_DIMS[1], IMAGE_DIMS[0],3))\n",
    "encoded_image = model(image_input)\n",
    "\n",
    "# 다음은 문제를 벡터로 인코딩할 숫자 모델을 정의합니다\n",
    "numeric_input = Input(shape=(2,))\n",
    "embedded_numeric = Embedding(input_dim=100, output_dim=256, input_length=2)(numeric_input)\n",
    "\n",
    "# numeric_input2 = Dense(256, activation=\"linear\")(embedded_numeric)\n",
    "# print(embedded_numeric.shape)\n",
    "\n",
    "#numeric_input2 = GRU(256)(embedded_numeric)\n",
    "numeric_input2 = GRU(256)(embedded_numeric)\n",
    "# print(numeric_input2.shape)\n",
    "\n",
    "\n",
    "# numeric_input = Input(shape=(8,), dtype='float32')\n",
    "# numeric_input1 = Dense(1000,activation='linear')(numeric_input)\n",
    "# numeric_input2 = Dense(100,activation='linear')(numeric_input1)\n",
    "\n",
    "# 질문 벡터와 이미지 벡터를 연결해 봅시다:\n",
    "merged = keras.layers.concatenate([encoded_image, numeric_input2],axis=-1)\n",
    "\n",
    "output = Dense(1)(merged)\n",
    "\n",
    "# 그리고 상층의 로지스틱 회귀를 수치에 대해 학습시킵니다:\n",
    "# output = Dense(1024, activation='softmax')(merged)\n",
    "# output = Dense(128, activation='softmax')(output)\n",
    "# output = Dense(1)(output)\n",
    "# 다음은 최종 모델입니다:\n",
    "model = Model(inputs=[image_input, numeric_input], outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "8948/8948 [==============================] - 35s 4ms/step - loss: 244.3261 - acc: 0.0067\n",
      "Epoch 2/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 165.4432 - acc: 0.0084\n",
      "Epoch 3/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 126.2024 - acc: 0.0105\n",
      "Epoch 4/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 104.3586 - acc: 0.0113\n",
      "Epoch 5/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 92.9719 - acc: 0.0117\n",
      "Epoch 6/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 77.3497 - acc: 0.0131\n",
      "Epoch 7/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 72.9745 - acc: 0.0134\n",
      "Epoch 8/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 67.2029 - acc: 0.0145\n",
      "Epoch 9/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 60.9029 - acc: 0.0150\n",
      "Epoch 10/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 53.4714 - acc: 0.0152\n",
      "Epoch 11/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 50.1841 - acc: 0.0174\n",
      "Epoch 12/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 45.1599 - acc: 0.0151\n",
      "Epoch 13/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 37.2699 - acc: 0.0180\n",
      "Epoch 14/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 35.2720 - acc: 0.0181\n",
      "Epoch 15/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 33.6069 - acc: 0.0174\n",
      "Epoch 16/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 31.4399 - acc: 0.0188\n",
      "Epoch 17/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 30.7209 - acc: 0.0198\n",
      "Epoch 18/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 31.3860 - acc: 0.0205\n",
      "Epoch 19/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 24.1621 - acc: 0.0211\n",
      "Epoch 20/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 24.7240 - acc: 0.0207\n",
      "Epoch 21/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 24.6091 - acc: 0.0232\n",
      "Epoch 22/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 20.6464 - acc: 0.0194\n",
      "Epoch 23/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 18.7334 - acc: 0.0212\n",
      "Epoch 24/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 17.8014 - acc: 0.0207\n",
      "Epoch 25/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 18.0685 - acc: 0.0215\n",
      "Epoch 26/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 18.4376 - acc: 0.0234\n",
      "Epoch 27/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 16.1780 - acc: 0.0234\n",
      "Epoch 28/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 15.1358 - acc: 0.0240\n",
      "Epoch 29/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 16.2967 - acc: 0.0237\n",
      "Epoch 30/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 13.7205 - acc: 0.0246\n",
      "Epoch 31/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 14.6636 - acc: 0.0234\n",
      "Epoch 32/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 15.0274 - acc: 0.0284\n",
      "Epoch 33/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 12.7267 - acc: 0.0279\n",
      "Epoch 34/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 12.8140 - acc: 0.0221\n",
      "Epoch 35/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 14.8106 - acc: 0.0244\n",
      "Epoch 36/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 11.6648 - acc: 0.0253\n",
      "Epoch 37/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 10.9401 - acc: 0.0276\n",
      "Epoch 38/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 11.1936 - acc: 0.0257\n",
      "Epoch 39/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 10.5647 - acc: 0.0301\n",
      "Epoch 40/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 10.5068 - acc: 0.0289\n",
      "Epoch 41/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 12.6279 - acc: 0.0278\n",
      "Epoch 42/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 9.2927 - acc: 0.0272\n",
      "Epoch 43/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 9.0471 - acc: 0.0273\n",
      "Epoch 44/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 10.7120 - acc: 0.0272\n",
      "Epoch 45/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.6225 - acc: 0.0286\n",
      "Epoch 46/200\n",
      "8948/8948 [==============================] - 32s 4ms/step - loss: 8.3678 - acc: 0.0293\n",
      "Epoch 47/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.7978 - acc: 0.0306\n",
      "Epoch 48/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 9.0013 - acc: 0.0300\n",
      "Epoch 49/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.3598 - acc: 0.0306\n",
      "Epoch 50/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 10.2121 - acc: 0.0273\n",
      "Epoch 51/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.5188 - acc: 0.0289\n",
      "Epoch 52/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.6071 - acc: 0.0300\n",
      "Epoch 53/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.4027 - acc: 0.0317\n",
      "Epoch 54/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.7153 - acc: 0.0316\n",
      "Epoch 55/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.7092 - acc: 0.0297\n",
      "Epoch 56/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.6031 - acc: 0.0340\n",
      "Epoch 57/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.7312 - acc: 0.0334\n",
      "Epoch 58/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.9677 - acc: 0.0345\n",
      "Epoch 59/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.4319 - acc: 0.0338\n",
      "Epoch 60/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.2474 - acc: 0.0317\n",
      "Epoch 61/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.0282 - acc: 0.0311\n",
      "Epoch 62/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.1472 - acc: 0.0322\n",
      "Epoch 63/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.7247 - acc: 0.0342\n",
      "Epoch 64/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.6422 - acc: 0.0317\n",
      "Epoch 65/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.4595 - acc: 0.0370\n",
      "Epoch 66/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.8525 - acc: 0.0369\n",
      "Epoch 67/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.1434 - acc: 0.0368\n",
      "Epoch 68/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.6475 - acc: 0.0342\n",
      "Epoch 69/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.1145 - acc: 0.0351\n",
      "Epoch 70/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.6496 - acc: 0.0358\n",
      "Epoch 71/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.8466 - acc: 0.0335\n",
      "Epoch 72/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.1230 - acc: 0.0371\n",
      "Epoch 73/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.7460 - acc: 0.0363\n",
      "Epoch 74/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.4411 - acc: 0.0381\n",
      "Epoch 75/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.5865 - acc: 0.0370\n",
      "Epoch 76/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.8030 - acc: 0.0358\n",
      "Epoch 77/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.3777 - acc: 0.0382\n",
      "Epoch 78/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.4763 - acc: 0.0374\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8948/8948 [==============================] - 32s 4ms/step - loss: 5.5966 - acc: 0.0360\n",
      "Epoch 80/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.9338 - acc: 0.0335\n",
      "Epoch 81/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.2406 - acc: 0.0343\n",
      "Epoch 82/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.0144 - acc: 0.0363\n",
      "Epoch 83/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.5583 - acc: 0.0336\n",
      "Epoch 84/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.7941 - acc: 0.0399\n",
      "Epoch 85/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.6997 - acc: 0.0354\n",
      "Epoch 86/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.7431 - acc: 0.0367\n",
      "Epoch 87/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.8572 - acc: 0.0371\n",
      "Epoch 88/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.4796 - acc: 0.0419\n",
      "Epoch 89/200\n",
      "8948/8948 [==============================] - 32s 4ms/step - loss: 6.2927 - acc: 0.0350\n",
      "Epoch 90/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.6140 - acc: 0.0316\n",
      "Epoch 91/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9073 - acc: 0.0419\n",
      "Epoch 92/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.6622 - acc: 0.0397\n",
      "Epoch 93/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.4097 - acc: 0.0374\n",
      "Epoch 94/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.1055 - acc: 0.0368\n",
      "Epoch 95/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.9333 - acc: 0.0419\n",
      "Epoch 96/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.1061 - acc: 0.0395\n",
      "Epoch 97/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.4506 - acc: 0.0395\n",
      "Epoch 98/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.0740 - acc: 0.0345\n",
      "Epoch 99/200\n",
      "8948/8948 [==============================] - 32s 4ms/step - loss: 5.8908 - acc: 0.0363\n",
      "Epoch 100/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.2376 - acc: 0.0415\n",
      "Epoch 101/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.1606 - acc: 0.0410\n",
      "Epoch 102/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.2369 - acc: 0.0405\n",
      "Epoch 103/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.7726 - acc: 0.0389\n",
      "Epoch 104/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.2375 - acc: 0.0393\n",
      "Epoch 105/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.6264 - acc: 0.0398\n",
      "Epoch 106/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.4808 - acc: 0.0415\n",
      "Epoch 107/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.1481 - acc: 0.0428\n",
      "Epoch 108/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.7369 - acc: 0.0422\n",
      "Epoch 109/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.1650 - acc: 0.0421\n",
      "Epoch 110/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.3628 - acc: 0.0420\n",
      "Epoch 111/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.3583 - acc: 0.0414\n",
      "Epoch 112/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.5467 - acc: 0.0380\n",
      "Epoch 113/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.3286 - acc: 0.0445\n",
      "Epoch 114/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.1722 - acc: 0.0444\n",
      "Epoch 115/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.0653 - acc: 0.0402\n",
      "Epoch 116/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.2064 - acc: 0.0400\n",
      "Epoch 117/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.3318 - acc: 0.0382\n",
      "Epoch 118/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9964 - acc: 0.0448\n",
      "Epoch 119/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.5697 - acc: 0.0434\n",
      "Epoch 120/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.2352 - acc: 0.0428\n",
      "Epoch 121/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9231 - acc: 0.0449\n",
      "Epoch 122/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9469 - acc: 0.0406\n",
      "Epoch 123/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.7488 - acc: 0.0449\n",
      "Epoch 124/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4692 - acc: 0.0437\n",
      "Epoch 125/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.0063 - acc: 0.0406\n",
      "Epoch 126/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.7394 - acc: 0.0447\n",
      "Epoch 127/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.8656 - acc: 0.0446\n",
      "Epoch 128/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.3604 - acc: 0.0421\n",
      "Epoch 129/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6055 - acc: 0.0474\n",
      "Epoch 130/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.7838 - acc: 0.0411\n",
      "Epoch 131/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.0923 - acc: 0.0450\n",
      "Epoch 132/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6677 - acc: 0.0430\n",
      "Epoch 133/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.4183 - acc: 0.0411\n",
      "Epoch 134/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.3783 - acc: 0.0387\n",
      "Epoch 135/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.6231 - acc: 0.0399\n",
      "Epoch 136/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.1057 - acc: 0.0415\n",
      "Epoch 137/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6434 - acc: 0.0450\n",
      "Epoch 138/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.3471 - acc: 0.0458\n",
      "Epoch 139/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.8153 - acc: 0.0457\n",
      "Epoch 140/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4494 - acc: 0.0436\n",
      "Epoch 141/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.2879 - acc: 0.0464\n",
      "Epoch 142/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6081 - acc: 0.0460\n",
      "Epoch 143/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.8599 - acc: 0.0440\n",
      "Epoch 144/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.3583 - acc: 0.0437\n",
      "Epoch 145/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.0865 - acc: 0.0477\n",
      "Epoch 146/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4426 - acc: 0.0511\n",
      "Epoch 147/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.1466 - acc: 0.0451\n",
      "Epoch 148/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4662 - acc: 0.0501\n",
      "Epoch 149/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.7618 - acc: 0.0449\n",
      "Epoch 150/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.2130 - acc: 0.0479\n",
      "Epoch 151/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.7279 - acc: 0.0439\n",
      "Epoch 152/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.8362 - acc: 0.0426\n",
      "Epoch 153/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.2105 - acc: 0.0472\n",
      "Epoch 154/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.3824 - acc: 0.0501\n",
      "Epoch 155/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.8550 - acc: 0.0467\n",
      "Epoch 156/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9911 - acc: 0.0432\n",
      "Epoch 157/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.9021 - acc: 0.0510\n",
      "Epoch 158/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.1620 - acc: 0.0467\n",
      "Epoch 159/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.7301 - acc: 0.0453\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9165 - acc: 0.0435\n",
      "Epoch 161/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.1166 - acc: 0.0467\n",
      "Epoch 162/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.1320 - acc: 0.0476\n",
      "Epoch 163/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4232 - acc: 0.0481\n",
      "Epoch 164/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6541 - acc: 0.0481\n",
      "Epoch 165/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.8041 - acc: 0.0464\n",
      "Epoch 166/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.8748 - acc: 0.0488\n",
      "Epoch 167/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.0011 - acc: 0.0493\n",
      "Epoch 168/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.9421 - acc: 0.0524\n",
      "Epoch 169/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.5177 - acc: 0.0467\n",
      "Epoch 170/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.5577 - acc: 0.0474\n",
      "Epoch 171/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.6713 - acc: 0.0517\n",
      "Epoch 172/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.1195 - acc: 0.0464\n",
      "Epoch 173/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.2615 - acc: 0.0481\n",
      "Epoch 174/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.3680 - acc: 0.0467\n",
      "Epoch 175/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.1198 - acc: 0.0495\n",
      "Epoch 176/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.8672 - acc: 0.0462\n",
      "Epoch 177/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.2358 - acc: 0.0508\n",
      "Epoch 178/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.8109 - acc: 0.0493\n",
      "Epoch 179/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.3913 - acc: 0.0492\n",
      "Epoch 180/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.8733 - acc: 0.0507\n",
      "Epoch 181/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.9258 - acc: 0.0481\n",
      "Epoch 182/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.0567 - acc: 0.0411\n",
      "Epoch 183/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.7496 - acc: 0.0511\n",
      "Epoch 184/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.2446 - acc: 0.0483\n",
      "Epoch 185/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.8289 - acc: 0.0459\n",
      "Epoch 186/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.5255 - acc: 0.0493\n",
      "Epoch 187/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.5643 - acc: 0.0457\n",
      "Epoch 188/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.2747 - acc: 0.0454\n",
      "Epoch 189/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4753 - acc: 0.0457\n",
      "Epoch 190/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.3429 - acc: 0.0440\n",
      "Epoch 191/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.7227 - acc: 0.0515\n",
      "Epoch 192/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.8135 - acc: 0.0479\n",
      "Epoch 193/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.9038 - acc: 0.0511\n",
      "Epoch 194/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.0375 - acc: 0.0497\n",
      "Epoch 195/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4273 - acc: 0.0519\n",
      "Epoch 196/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.5465 - acc: 0.0485\n",
      "Epoch 197/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.2761 - acc: 0.0476\n",
      "Epoch 198/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.8406 - acc: 0.0492\n",
      "Epoch 199/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.0748 - acc: 0.0482\n",
      "Epoch 200/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.9054 - acc: 0.0487\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "#opt = RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "opt = Adam(lr=0.002, epsilon=None, decay=0.0)\n",
    "model.compile(loss=\"mse\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "# logcosh, mes, \n",
    "H = model.fit([train_img,train_wea], train_val ,batch_size=10, epochs=200)\n",
    "\n",
    "\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save('new-LSTM-adam.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11186, 250, 350, 3)\n",
      "(11186,)\n",
      "(11186,)\n",
      "(11186,)\n",
      "(2238, 250, 350, 3)\n",
      "(2238, 2)\n",
      "[[44.210358 ]\n",
      " [42.493183 ]\n",
      " [46.260468 ]\n",
      " ...\n",
      " [ 5.2337265]\n",
      " [ 6.507616 ]\n",
      " [ 7.703509 ]]\n",
      "(2238,)\n",
      "(2238,)\n",
      "[52 55 55 ...  3  4  4]\n",
      "[44 42 46 ...  5  6  7]\n"
     ]
    }
   ],
   "source": [
    "print(image_arr.shape)\n",
    "print(dust_arr.shape)\n",
    "\n",
    "print(wind_arr.shape)\n",
    "print(humi_arr.shape)\n",
    "\n",
    "print(test_img.shape)\n",
    "print(test_wea.shape)\n",
    "\n",
    "print(model.predict([test_img, test_wea]))\n",
    "\n",
    "y_pred = np.squeeze(np.round(model.predict([test_img, test_wea]).astype(np.int64)))\n",
    "\n",
    "print(test_val.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "print(np.round(test_val.astype(np.int64)))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 는 :  32.734777892115176\n",
      "R2SCORE 는 :  -0.00676177988958182\n"
     ]
    }
   ],
   "source": [
    "RMSE = mean_squared_error(test_val.astype(np.int64), y_pred)**0.5\n",
    "R2SCORE = r2_score(test_val.astype(np.int64), y_pred)\n",
    "\n",
    "print(\"RMSE 는 : \" , RMSE)\n",
    "print(\"R2SCORE 는 : \", R2SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(70, 50, 'R-squared = -0.01')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_val=np.squeeze(test_val.astype(np.int64))\n",
    "\n",
    "plt.scatter(test_val,y_pred)\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "\n",
    "plt.plot(np.unique(test_val), np.poly1d(np.polyfit(test_val, y_pred, 1))(np.unique(test_val)))\n",
    "\n",
    "plt.text(70, 50, 'R-squared = %0.2f' % R2SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52, 55, 55, ...,  3,  4,  4], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(test_val.astype(np.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44, 42, 46, ...,  5,  6,  7], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
