{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from PIL import Image\n",
    "from imutils import paths\n",
    "from os import path\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "import pandas as pd\n",
    "keras.__version__\n",
    "IMAGE_DIMS = (350,250,3)\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_arr = np.load('./new_date_arr.npy',allow_pickle=True)\n",
    "dust_arr = np.load('./ultra_result_arr_avg_5.npy',allow_pickle=True)\n",
    "wind_arr = np.load('./wind_arr.npy',allow_pickle=True)\n",
    "humi_arr = np.load('./humi_arr.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 18126 images (22940.04MB)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time() \n",
    "imagePaths = sorted(list(paths.list_images('./dataset/image')))\n",
    "image_arr = []\n",
    "\n",
    "for i in imagePaths:\n",
    "    img_name = int(path.splitext(path.basename(i))[0])\n",
    "    \n",
    "    if img_name in date_arr :\n",
    "        image = Image.open(i)\n",
    "        image = image.resize((IMAGE_DIMS[0],IMAGE_DIMS[1]))\n",
    "        image = img_to_array(image)\n",
    "        image_arr.append(image)\n",
    "        \n",
    "image_arr = np.array(image_arr, dtype=\"float\") / 255.0        \n",
    "print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(len(imagePaths), image_arr.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11186,)\n",
      "(11186, 250, 350, 3)\n",
      "(10067, 250, 350, 3)\n",
      "(1119, 250, 350, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "con_data_img = image_arr\n",
    "con_data_val = dust_arr\n",
    "\n",
    "print(wind_arr.shape)\n",
    "con_data_wea = np.concatenate([wind_arr.reshape(len(wind_arr),1),humi_arr.reshape(len(humi_arr),1)], axis=1)\n",
    "\n",
    "\n",
    "# 국내는 PM2.5이 16이상이면 보통\n",
    "# for i in range(0,dustvalue.shape[0]):\n",
    "#     if int(dustvalue[i]) > 0 :\n",
    "#         con_data_img.append(data[i])\n",
    "#         con_data_val.append(dustvalue[i])\n",
    "#         con_data_wea.append(add_info[i])\n",
    "        \n",
    "# con_data_img, con_data_val, con_data_wea = shuffle(np.array(con_data_img), np.array(con_data_val), np.array(con_data_wea), random_state=0)\n",
    "# con_data_img = np.array(con_data_img)\n",
    "# con_data_val = np.array(con_data_val)\n",
    "# con_data_wea = np.array(con_data_wea)\n",
    "\n",
    "num = int(con_data_img.shape[0]*0.9)\n",
    "\n",
    "train_img = con_data_img[:num]\n",
    "train_val = con_data_val[:num]\n",
    "train_wea = con_data_wea[:num]\n",
    "\n",
    "test_img = con_data_img[num:]\n",
    "test_val = con_data_val[num:]\n",
    "test_wea = con_data_wea[num:]\n",
    "\n",
    "print(con_data_img.shape)\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, LSTM, GRU, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "chanDim=-1\n",
    "model = Sequential()\n",
    "\n",
    "# CONV => RELU => POOL\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(IMAGE_DIMS[1], IMAGE_DIMS[0],3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "image_input = Input(shape=(IMAGE_DIMS[1], IMAGE_DIMS[0],3))\n",
    "encoded_image = model(image_input)\n",
    "\n",
    "# 다음은 문제를 벡터로 인코딩할 숫자 모델을 정의합니다\n",
    "numeric_input = Input(shape=(2,))\n",
    "embedded_numeric = Embedding(input_dim=100, output_dim=256, input_length=2)(numeric_input)\n",
    "\n",
    "# numeric_input2 = Dense(256, activation=\"linear\")(embedded_numeric)\n",
    "# print(embedded_numeric.shape)\n",
    "\n",
    "#numeric_input2 = GRU(256)(embedded_numeric)\n",
    "numeric_input2 = GRU(256)(embedded_numeric)\n",
    "# print(numeric_input2.shape)\n",
    "\n",
    "\n",
    "# numeric_input = Input(shape=(8,), dtype='float32')\n",
    "# numeric_input1 = Dense(1000,activation='linear')(numeric_input)\n",
    "# numeric_input2 = Dense(100,activation='linear')(numeric_input1)\n",
    "\n",
    "# 질문 벡터와 이미지 벡터를 연결해 봅시다:\n",
    "merged = keras.layers.concatenate([encoded_image, numeric_input2],axis=-1)\n",
    "\n",
    "output = Dense(1)(merged)\n",
    "\n",
    "# 그리고 상층의 로지스틱 회귀를 수치에 대해 학습시킵니다:\n",
    "# output = Dense(1024, activation='softmax')(merged)\n",
    "# output = Dense(128, activation='softmax')(output)\n",
    "# output = Dense(1)(output)\n",
    "# 다음은 최종 모델입니다:\n",
    "model = Model(inputs=[image_input, numeric_input], outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "10067/10067 [==============================] - 44s 4ms/step - loss: 238.4982 - acc: 0.0118\n",
      "Epoch 2/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 180.2647 - acc: 0.0153\n",
      "Epoch 3/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 162.9343 - acc: 0.0160\n",
      "Epoch 4/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 146.8140 - acc: 0.0199\n",
      "Epoch 5/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 135.6074 - acc: 0.0205\n",
      "Epoch 6/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 129.7226 - acc: 0.0241\n",
      "Epoch 7/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 123.7737 - acc: 0.0236\n",
      "Epoch 8/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 120.2062 - acc: 0.0212\n",
      "Epoch 9/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 113.4859 - acc: 0.0229\n",
      "Epoch 10/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 109.3073 - acc: 0.0244\n",
      "Epoch 11/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 96.2678 - acc: 0.0240\n",
      "Epoch 12/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 99.2233 - acc: 0.0243\n",
      "Epoch 13/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 95.4883 - acc: 0.0214\n",
      "Epoch 14/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 89.3398 - acc: 0.0249\n",
      "Epoch 15/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 86.7002 - acc: 0.0234\n",
      "Epoch 16/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 78.6475 - acc: 0.0206\n",
      "Epoch 17/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 64.6232 - acc: 0.0231\n",
      "Epoch 18/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 73.3844 - acc: 0.0264\n",
      "Epoch 19/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 63.4943 - acc: 0.0287\n",
      "Epoch 20/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 53.5499 - acc: 0.0269\n",
      "Epoch 21/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 58.5171 - acc: 0.0242\n",
      "Epoch 22/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 57.3157 - acc: 0.0230\n",
      "Epoch 23/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 46.3646 - acc: 0.0290\n",
      "Epoch 24/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 44.1762 - acc: 0.0277\n",
      "Epoch 25/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 39.1802 - acc: 0.0255\n",
      "Epoch 26/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 39.8198 - acc: 0.0261\n",
      "Epoch 27/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 33.5010 - acc: 0.0303\n",
      "Epoch 28/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 35.0935 - acc: 0.0314\n",
      "Epoch 29/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 35.2992 - acc: 0.0320\n",
      "Epoch 30/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 26.0240 - acc: 0.0288\n",
      "Epoch 31/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 23.9828 - acc: 0.0338\n",
      "Epoch 32/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 33.0419 - acc: 0.0337\n",
      "Epoch 33/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 34.7861 - acc: 0.0295\n",
      "Epoch 34/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 30.2024 - acc: 0.0325\n",
      "Epoch 35/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 23.8542 - acc: 0.0320\n",
      "Epoch 36/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 26.9810 - acc: 0.0342\n",
      "Epoch 37/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 27.3461 - acc: 0.0322\n",
      "Epoch 38/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 26.0452 - acc: 0.0323\n",
      "Epoch 39/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 21.9561 - acc: 0.0350\n",
      "Epoch 40/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 18.0576 - acc: 0.0413\n",
      "Epoch 41/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 19.0039 - acc: 0.0377\n",
      "Epoch 42/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 21.8891 - acc: 0.0380\n",
      "Epoch 43/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 16.4736 - acc: 0.0368\n",
      "Epoch 44/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 19.1129 - acc: 0.0385\n",
      "Epoch 45/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 15.6880 - acc: 0.0384\n",
      "Epoch 46/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 15.7420 - acc: 0.0378\n",
      "Epoch 47/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 21.1473 - acc: 0.0343\n",
      "Epoch 48/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.8444 - acc: 0.0429\n",
      "Epoch 49/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 12.8216 - acc: 0.0413\n",
      "Epoch 50/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 14.5556 - acc: 0.0419\n",
      "Epoch 51/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 19.7884 - acc: 0.0397\n",
      "Epoch 52/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 12.8624 - acc: 0.0443\n",
      "Epoch 53/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.6508 - acc: 0.0404\n",
      "Epoch 54/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.1032 - acc: 0.0435\n",
      "Epoch 55/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.4460 - acc: 0.0434\n",
      "Epoch 56/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 10.9244 - acc: 0.0456\n",
      "Epoch 57/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 25.8525 - acc: 0.0360\n",
      "Epoch 58/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 23.0450 - acc: 0.0433\n",
      "Epoch 59/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 19.0375 - acc: 0.0414\n",
      "Epoch 60/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.9301 - acc: 0.0406\n",
      "Epoch 61/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 33.8507 - acc: 0.0339\n",
      "Epoch 62/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 15.8029 - acc: 0.0389\n",
      "Epoch 63/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.3806 - acc: 0.0392\n",
      "Epoch 64/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 11.1145 - acc: 0.0430\n",
      "Epoch 65/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 15.6339 - acc: 0.0401\n",
      "Epoch 66/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 15.8608 - acc: 0.0403\n",
      "Epoch 67/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 11.6272 - acc: 0.0402\n",
      "Epoch 68/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.7263 - acc: 0.0426\n",
      "Epoch 69/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 15.9880 - acc: 0.0400\n",
      "Epoch 70/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 9.9416 - acc: 0.0473\n",
      "Epoch 71/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 8.4300 - acc: 0.0465\n",
      "Epoch 72/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.8717 - acc: 0.0439\n",
      "Epoch 73/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.6106 - acc: 0.0448\n",
      "Epoch 74/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 17.6721 - acc: 0.0441\n",
      "Epoch 75/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 13.0761 - acc: 0.0408\n",
      "Epoch 76/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 13.0341 - acc: 0.0468\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10067/10067 [==============================] - 40s 4ms/step - loss: 8.3752 - acc: 0.0501\n",
      "Epoch 78/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 9.7437 - acc: 0.0456\n",
      "Epoch 79/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 8.4237 - acc: 0.0492\n",
      "Epoch 80/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 8.9859 - acc: 0.0503\n",
      "Epoch 81/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.1332 - acc: 0.0497\n",
      "Epoch 82/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 14.7142 - acc: 0.0447\n",
      "Epoch 83/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 17.1511 - acc: 0.0426\n",
      "Epoch 84/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.6145 - acc: 0.0434\n",
      "Epoch 85/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 11.5154 - acc: 0.0506\n",
      "Epoch 86/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 10.6116 - acc: 0.0440\n",
      "Epoch 87/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 7.5288 - acc: 0.0516\n",
      "Epoch 88/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 7.7586 - acc: 0.0509\n",
      "Epoch 89/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.6264 - acc: 0.0542\n",
      "Epoch 90/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.2601 - acc: 0.0435\n",
      "Epoch 91/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 17.7866 - acc: 0.0437\n",
      "Epoch 92/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.1398 - acc: 0.0440\n",
      "Epoch 93/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.1762 - acc: 0.0478\n",
      "Epoch 94/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 6.1903 - acc: 0.0495\n",
      "Epoch 95/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.4228 - acc: 0.0509\n",
      "Epoch 96/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.3336 - acc: 0.0522\n",
      "Epoch 97/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 7.5444 - acc: 0.0554\n",
      "Epoch 98/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 8.0441 - acc: 0.0506\n",
      "Epoch 99/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 7.4539 - acc: 0.0546\n",
      "Epoch 100/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 8.8157 - acc: 0.0522\n",
      "Epoch 101/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 9.8770 - acc: 0.0481\n",
      "Epoch 102/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 6.5895 - acc: 0.0541\n",
      "Epoch 103/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 8.3601 - acc: 0.0530\n",
      "Epoch 104/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 7.5611 - acc: 0.0537\n",
      "Epoch 105/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.1948 - acc: 0.0550\n",
      "Epoch 106/200\n",
      "10067/10067 [==============================] - 42s 4ms/step - loss: 5.9532 - acc: 0.0535\n",
      "Epoch 107/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 6.5705 - acc: 0.0593\n",
      "Epoch 108/200\n",
      "10067/10067 [==============================] - 43s 4ms/step - loss: 7.4730 - acc: 0.0585\n",
      "Epoch 109/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 6.7456 - acc: 0.0533\n",
      "Epoch 110/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 15.3465 - acc: 0.0488\n",
      "Epoch 111/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.8123 - acc: 0.0468\n",
      "Epoch 112/200\n",
      "10067/10067 [==============================] - 42s 4ms/step - loss: 6.6156 - acc: 0.0487\n",
      "Epoch 113/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 8.1496 - acc: 0.0488\n",
      "Epoch 114/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 8.5595 - acc: 0.0523\n",
      "Epoch 115/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 9.6281 - acc: 0.0539\n",
      "Epoch 116/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 7.8766 - acc: 0.0533\n",
      "Epoch 117/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 7.6415 - acc: 0.0582\n",
      "Epoch 118/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.9834 - acc: 0.0518\n",
      "Epoch 119/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 7.4696 - acc: 0.0561\n",
      "Epoch 120/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 8.0777 - acc: 0.0557\n",
      "Epoch 121/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.8856 - acc: 0.0601\n",
      "Epoch 122/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 8.4290 - acc: 0.0541\n",
      "Epoch 123/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.1162 - acc: 0.0605\n",
      "Epoch 124/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 11.1236 - acc: 0.0481\n",
      "Epoch 125/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 10.8936 - acc: 0.0493\n",
      "Epoch 126/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.5918 - acc: 0.0625\n",
      "Epoch 127/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.6485 - acc: 0.0610\n",
      "Epoch 128/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.5595 - acc: 0.0621\n",
      "Epoch 129/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.1690 - acc: 0.0586\n",
      "Epoch 130/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 7.0415 - acc: 0.0566\n",
      "Epoch 131/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 8.1426 - acc: 0.0611\n",
      "Epoch 132/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.6622 - acc: 0.0586\n",
      "Epoch 133/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.6330 - acc: 0.0524\n",
      "Epoch 134/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 8.4068 - acc: 0.0568\n",
      "Epoch 135/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.6343 - acc: 0.0584\n",
      "Epoch 136/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.3151 - acc: 0.0617\n",
      "Epoch 137/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 4.9011 - acc: 0.0633\n",
      "Epoch 138/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 19.0540 - acc: 0.0449\n",
      "Epoch 139/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.1011 - acc: 0.0477\n",
      "Epoch 140/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 8.2314 - acc: 0.0519\n",
      "Epoch 141/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 7.0047 - acc: 0.0523\n",
      "Epoch 142/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.6230 - acc: 0.0574\n",
      "Epoch 143/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.1521 - acc: 0.0598\n",
      "Epoch 144/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.7534 - acc: 0.0581\n",
      "Epoch 145/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 6.2713 - acc: 0.0616\n",
      "Epoch 146/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.0807 - acc: 0.0577\n",
      "Epoch 147/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.3271 - acc: 0.0594\n",
      "Epoch 148/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.8919 - acc: 0.0605\n",
      "Epoch 149/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.4846 - acc: 0.0559\n",
      "Epoch 150/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.6185 - acc: 0.0589\n",
      "Epoch 151/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.4148 - acc: 0.0617\n",
      "Epoch 152/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 7.1821 - acc: 0.0630\n",
      "Epoch 153/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.3598 - acc: 0.0566\n",
      "Epoch 154/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.7183 - acc: 0.0572\n",
      "Epoch 155/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.6574 - acc: 0.0565\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10067/10067 [==============================] - 41s 4ms/step - loss: 4.1981 - acc: 0.0621\n",
      "Epoch 157/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.6733 - acc: 0.0607\n",
      "Epoch 158/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 7.8210 - acc: 0.0576\n",
      "Epoch 159/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 3.9187 - acc: 0.0632\n",
      "Epoch 160/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.2802 - acc: 0.0666\n",
      "Epoch 161/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.8164 - acc: 0.0627\n",
      "Epoch 162/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.2879 - acc: 0.0597\n",
      "Epoch 163/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.1355 - acc: 0.0631\n",
      "Epoch 164/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.0392 - acc: 0.0671\n",
      "Epoch 165/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.6164 - acc: 0.0627\n",
      "Epoch 166/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 4.7437 - acc: 0.0606\n",
      "Epoch 167/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.5369 - acc: 0.0630\n",
      "Epoch 168/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 3.2379 - acc: 0.0666\n",
      "Epoch 169/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 4.5324 - acc: 0.0670\n",
      "Epoch 170/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 3.6535 - acc: 0.0648\n",
      "Epoch 171/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 8.9224 - acc: 0.0569\n",
      "Epoch 172/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.1160 - acc: 0.0585\n",
      "Epoch 173/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 3.9457 - acc: 0.0636\n",
      "Epoch 174/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 7.8198 - acc: 0.0541\n",
      "Epoch 175/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 4.3714 - acc: 0.0608\n",
      "Epoch 176/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.3444 - acc: 0.0675\n",
      "Epoch 177/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 3.5123 - acc: 0.0678\n",
      "Epoch 178/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.6682 - acc: 0.0650\n",
      "Epoch 179/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.6520 - acc: 0.0677\n",
      "Epoch 180/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.1885 - acc: 0.0653\n",
      "Epoch 181/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.5317 - acc: 0.0655\n",
      "Epoch 182/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.2478 - acc: 0.0659\n",
      "Epoch 183/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 5.2236 - acc: 0.0609\n",
      "Epoch 184/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.9283 - acc: 0.0596\n",
      "Epoch 185/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.0406 - acc: 0.0657\n",
      "Epoch 186/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 3.7009 - acc: 0.0700\n",
      "Epoch 187/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.0663 - acc: 0.0706\n",
      "Epoch 188/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 3.2057 - acc: 0.0742\n",
      "Epoch 189/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 3.3876 - acc: 0.0705\n",
      "Epoch 190/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 3.6979 - acc: 0.0675\n",
      "Epoch 191/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.8324 - acc: 0.0622\n",
      "Epoch 192/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.7830 - acc: 0.0680\n",
      "Epoch 193/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 5.1195 - acc: 0.0676\n",
      "Epoch 194/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.0498 - acc: 0.0714\n",
      "Epoch 195/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.5807 - acc: 0.0672\n",
      "Epoch 196/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 3.3111 - acc: 0.0705\n",
      "Epoch 197/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 3.5129 - acc: 0.0721\n",
      "Epoch 198/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 4.0887 - acc: 0.0721\n",
      "Epoch 199/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 3.3170 - acc: 0.0718\n",
      "Epoch 200/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 3.2102 - acc: 0.0702\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "#opt = RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "opt = Adam(lr=0.002, epsilon=None, decay=0.0)\n",
    "model.compile(loss=\"mse\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "# logcosh, mes, \n",
    "H = model.fit([train_img,train_wea], train_val ,batch_size=10, epochs=200)\n",
    "\n",
    "\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save('new-ultra-LSTM-adam-5.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11186, 250, 350, 3)\n",
      "(11186,)\n",
      "(11186,)\n",
      "(11186,)\n",
      "(1119, 250, 350, 3)\n",
      "(1119, 2)\n",
      "[[6.394677 ]\n",
      " [3.092186 ]\n",
      " [4.9504824]\n",
      " ...\n",
      " [2.7946806]\n",
      " [6.7791853]\n",
      " [6.244216 ]]\n",
      "(1119,)\n",
      "(1119,)\n",
      "[2 3 3 ... 3 3 3]\n",
      "[6 3 4 ... 2 6 6]\n"
     ]
    }
   ],
   "source": [
    "print(image_arr.shape)\n",
    "print(dust_arr.shape)\n",
    "\n",
    "print(wind_arr.shape)\n",
    "print(humi_arr.shape)\n",
    "\n",
    "print(test_img.shape)\n",
    "print(test_wea.shape)\n",
    "\n",
    "print(model.predict([test_img, test_wea]))\n",
    "\n",
    "y_pred = np.squeeze(np.round(model.predict([test_img, test_wea]).astype(np.int64)))\n",
    "\n",
    "print(test_val.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "print(np.round(test_val.astype(np.int64)))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 는 :  11.669411141511537\n",
      "R2SCORE 는 :  0.031561656427100626\n"
     ]
    }
   ],
   "source": [
    "RMSE = mean_squared_error(test_val.astype(np.int64), y_pred)**0.5\n",
    "R2SCORE = r2_score(test_val.astype(np.int64), y_pred)\n",
    "\n",
    "print(\"RMSE 는 : \" , RMSE)\n",
    "print(\"R2SCORE 는 : \", R2SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(10, 5, 'R-squared = 0.03')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_val=np.squeeze(test_val.astype(np.int64))\n",
    "\n",
    "plt.scatter(test_val,y_pred)\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "\n",
    "plt.plot(np.unique(test_val), np.poly1d(np.polyfit(test_val, y_pred, 1))(np.unique(test_val)))\n",
    "\n",
    "plt.text(70, 50, 'R-squared = %0.2f' % R2SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(test_val.astype(np.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 4, ..., 2, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
