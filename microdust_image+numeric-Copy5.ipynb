{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from PIL import Image\n",
    "from imutils import paths\n",
    "from os import path\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "import pandas as pd\n",
    "keras.__version__\n",
    "IMAGE_DIMS = (350,250,3)\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_arr = np.load('./new_date_arr.npy',allow_pickle=True)\n",
    "dust_arr = np.load('./ultra_result_arr.npy',allow_pickle=True)\n",
    "wind_arr = np.load('./wind_arr.npy',allow_pickle=True)\n",
    "humi_arr = np.load('./humi_arr.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 18126 images (22940.04MB)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time() \n",
    "imagePaths = sorted(list(paths.list_images('./dataset/image')))\n",
    "image_arr = []\n",
    "\n",
    "for i in imagePaths:\n",
    "    img_name = int(path.splitext(path.basename(i))[0])\n",
    "    \n",
    "    if img_name in date_arr :\n",
    "        image = Image.open(i)\n",
    "        image = image.resize((IMAGE_DIMS[0],IMAGE_DIMS[1]))\n",
    "        image = img_to_array(image)\n",
    "        image_arr.append(image)\n",
    "        \n",
    "image_arr = np.array(image_arr, dtype=\"float\") / 255.0        \n",
    "print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(len(imagePaths), image_arr.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11186,)\n",
      "(11186, 250, 350, 3)\n",
      "(10067, 250, 350, 3)\n",
      "(1119, 250, 350, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "con_data_img = image_arr\n",
    "con_data_val = dust_arr\n",
    "\n",
    "print(wind_arr.shape)\n",
    "con_data_wea = np.concatenate([wind_arr.reshape(len(wind_arr),1),humi_arr.reshape(len(humi_arr),1)], axis=1)\n",
    "\n",
    "\n",
    "# 국내는 PM2.5이 16이상이면 보통\n",
    "# for i in range(0,dustvalue.shape[0]):\n",
    "#     if int(dustvalue[i]) > 0 :\n",
    "#         con_data_img.append(data[i])\n",
    "#         con_data_val.append(dustvalue[i])\n",
    "#         con_data_wea.append(add_info[i])\n",
    "        \n",
    "# con_data_img, con_data_val, con_data_wea = shuffle(np.array(con_data_img), np.array(con_data_val), np.array(con_data_wea), random_state=0)\n",
    "# con_data_img = np.array(con_data_img)\n",
    "# con_data_val = np.array(con_data_val)\n",
    "# con_data_wea = np.array(con_data_wea)\n",
    "\n",
    "num = int(con_data_img.shape[0]*0.9)\n",
    "\n",
    "train_img = con_data_img[:num]\n",
    "train_val = con_data_val[:num]\n",
    "train_wea = con_data_wea[:num]\n",
    "\n",
    "test_img = con_data_img[num:]\n",
    "test_val = con_data_val[num:]\n",
    "test_wea = con_data_wea[num:]\n",
    "\n",
    "print(con_data_img.shape)\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, LSTM, GRU, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "chanDim=-1\n",
    "model = Sequential()\n",
    "\n",
    "# CONV => RELU => POOL\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(IMAGE_DIMS[1], IMAGE_DIMS[0],3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "image_input = Input(shape=(IMAGE_DIMS[1], IMAGE_DIMS[0],3))\n",
    "encoded_image = model(image_input)\n",
    "\n",
    "# 다음은 문제를 벡터로 인코딩할 숫자 모델을 정의합니다\n",
    "numeric_input = Input(shape=(2,))\n",
    "embedded_numeric = Embedding(input_dim=100, output_dim=256, input_length=2)(numeric_input)\n",
    "\n",
    "# numeric_input2 = Dense(256, activation=\"linear\")(embedded_numeric)\n",
    "# print(embedded_numeric.shape)\n",
    "\n",
    "#numeric_input2 = GRU(256)(embedded_numeric)\n",
    "numeric_input2 = GRU(256)(embedded_numeric)\n",
    "# print(numeric_input2.shape)\n",
    "\n",
    "\n",
    "# numeric_input = Input(shape=(8,), dtype='float32')\n",
    "# numeric_input1 = Dense(1000,activation='linear')(numeric_input)\n",
    "# numeric_input2 = Dense(100,activation='linear')(numeric_input1)\n",
    "\n",
    "# 질문 벡터와 이미지 벡터를 연결해 봅시다:\n",
    "merged = keras.layers.concatenate([encoded_image, numeric_input2],axis=-1)\n",
    "\n",
    "output = Dense(1)(merged)\n",
    "\n",
    "# 그리고 상층의 로지스틱 회귀를 수치에 대해 학습시킵니다:\n",
    "# output = Dense(1024, activation='softmax')(merged)\n",
    "# output = Dense(128, activation='softmax')(output)\n",
    "# output = Dense(1)(output)\n",
    "# 다음은 최종 모델입니다:\n",
    "model = Model(inputs=[image_input, numeric_input], outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "10067/10067 [==============================] - 45s 4ms/step - loss: 554.0100 - acc: 0.0466\n",
      "Epoch 2/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 476.8829 - acc: 0.0631\n",
      "Epoch 3/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 451.7001 - acc: 0.0759\n",
      "Epoch 4/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 439.9758 - acc: 0.0808\n",
      "Epoch 5/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 431.9165 - acc: 0.0845\n",
      "Epoch 6/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 429.8383 - acc: 0.0897\n",
      "Epoch 7/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 425.8717 - acc: 0.0925\n",
      "Epoch 8/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 418.1292 - acc: 0.0897\n",
      "Epoch 9/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 408.1211 - acc: 0.0892\n",
      "Epoch 10/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 402.8649 - acc: 0.0944\n",
      "Epoch 11/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 403.6968 - acc: 0.0851\n",
      "Epoch 12/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 390.9597 - acc: 0.0839\n",
      "Epoch 13/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 386.8714 - acc: 0.0846\n",
      "Epoch 14/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 381.4074 - acc: 0.0762\n",
      "Epoch 15/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 380.0898 - acc: 0.0838\n",
      "Epoch 16/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 360.2657 - acc: 0.0811\n",
      "Epoch 17/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 357.5594 - acc: 0.0762\n",
      "Epoch 18/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 350.8319 - acc: 0.0729\n",
      "Epoch 19/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 324.0098 - acc: 0.0748\n",
      "Epoch 20/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 308.9294 - acc: 0.0632\n",
      "Epoch 21/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 317.3882 - acc: 0.0701\n",
      "Epoch 22/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 293.1463 - acc: 0.0706\n",
      "Epoch 23/200\n",
      "10067/10067 [==============================] - 43s 4ms/step - loss: 234.8806 - acc: 0.0647\n",
      "Epoch 24/200\n",
      "10067/10067 [==============================] - 43s 4ms/step - loss: 182.8900 - acc: 0.0650\n",
      "Epoch 25/200\n",
      "10067/10067 [==============================] - 43s 4ms/step - loss: 195.6240 - acc: 0.0776\n",
      "Epoch 26/200\n",
      "10067/10067 [==============================] - 43s 4ms/step - loss: 204.7116 - acc: 0.0661\n",
      "Epoch 27/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 139.9768 - acc: 0.0699\n",
      "Epoch 28/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 126.6659 - acc: 0.0752\n",
      "Epoch 29/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 130.6300 - acc: 0.0806\n",
      "Epoch 30/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 174.7496 - acc: 0.0692\n",
      "Epoch 31/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 96.0766 - acc: 0.0854\n",
      "Epoch 32/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 145.4579 - acc: 0.0905\n",
      "Epoch 33/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 275.4096 - acc: 0.0706\n",
      "Epoch 34/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 109.0900 - acc: 0.0782\n",
      "Epoch 35/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 101.2263 - acc: 0.0796\n",
      "Epoch 36/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 99.2677 - acc: 0.0791\n",
      "Epoch 37/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 160.9499 - acc: 0.0788\n",
      "Epoch 38/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 105.0018 - acc: 0.0850\n",
      "Epoch 39/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 101.1228 - acc: 0.0847\n",
      "Epoch 40/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 71.9138 - acc: 0.0837\n",
      "Epoch 41/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 122.5108 - acc: 0.0773\n",
      "Epoch 42/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 62.5366 - acc: 0.0941\n",
      "Epoch 43/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 102.5961 - acc: 0.0726\n",
      "Epoch 44/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 89.2636 - acc: 0.0815\n",
      "Epoch 45/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 145.1952 - acc: 0.0771\n",
      "Epoch 46/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 80.3145 - acc: 0.0858\n",
      "Epoch 47/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 93.6964 - acc: 0.0856\n",
      "Epoch 48/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 96.4361 - acc: 0.0871\n",
      "Epoch 49/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 78.1289 - acc: 0.0819\n",
      "Epoch 50/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 132.9621 - acc: 0.0888\n",
      "Epoch 51/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 72.2037 - acc: 0.0927\n",
      "Epoch 52/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 58.4118 - acc: 0.0914\n",
      "Epoch 53/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 48.5373 - acc: 0.0970\n",
      "Epoch 54/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 74.6577 - acc: 0.0875\n",
      "Epoch 55/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 80.4491 - acc: 0.0946\n",
      "Epoch 56/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 45.3581 - acc: 0.1055\n",
      "Epoch 57/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 40.4674 - acc: 0.1016\n",
      "Epoch 58/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 69.3514 - acc: 0.1060\n",
      "Epoch 59/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 61.2844 - acc: 0.1161\n",
      "Epoch 60/200\n",
      "10067/10067 [==============================] - 42s 4ms/step - loss: 44.6658 - acc: 0.1061\n",
      "Epoch 61/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 51.4642 - acc: 0.1017\n",
      "Epoch 62/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 75.4795 - acc: 0.0997\n",
      "Epoch 63/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 39.9231 - acc: 0.1116\n",
      "Epoch 64/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 43.9764 - acc: 0.1162\n",
      "Epoch 65/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 28.7991 - acc: 0.1236\n",
      "Epoch 66/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 49.9757 - acc: 0.1194\n",
      "Epoch 67/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 46.2274 - acc: 0.1139\n",
      "Epoch 68/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 41.9578 - acc: 0.1224\n",
      "Epoch 69/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 34.2196 - acc: 0.1164\n",
      "Epoch 70/200\n",
      "10067/10067 [==============================] - 42s 4ms/step - loss: 99.4089 - acc: 0.1130\n",
      "Epoch 71/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 41.1577 - acc: 0.1069\n",
      "Epoch 72/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 29.0226 - acc: 0.1277\n",
      "Epoch 73/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 28.9046 - acc: 0.1279\n",
      "Epoch 74/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 51.7350 - acc: 0.1269\n",
      "Epoch 75/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 29.8697 - acc: 0.1268\n",
      "Epoch 76/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 25.0420 - acc: 0.1379\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10067/10067 [==============================] - 40s 4ms/step - loss: 29.8252 - acc: 0.1381\n",
      "Epoch 78/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 28.1366 - acc: 0.1363\n",
      "Epoch 79/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 34.9224 - acc: 0.1323\n",
      "Epoch 80/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 38.3860 - acc: 0.1347\n",
      "Epoch 81/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 33.0547 - acc: 0.1357\n",
      "Epoch 82/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 22.5548 - acc: 0.1385\n",
      "Epoch 83/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 34.8479 - acc: 0.1343\n",
      "Epoch 84/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 30.3470 - acc: 0.1307\n",
      "Epoch 85/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 19.9285 - acc: 0.1405\n",
      "Epoch 86/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 21.4385 - acc: 0.1480\n",
      "Epoch 87/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 22.2014 - acc: 0.1491\n",
      "Epoch 88/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 26.7614 - acc: 0.1465\n",
      "Epoch 89/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 22.1788 - acc: 0.1455\n",
      "Epoch 90/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 27.8012 - acc: 0.1364\n",
      "Epoch 91/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 19.6763 - acc: 0.1584\n",
      "Epoch 92/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 18.9630 - acc: 0.1550\n",
      "Epoch 93/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 22.3780 - acc: 0.1516\n",
      "Epoch 94/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 26.3451 - acc: 0.1433\n",
      "Epoch 95/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 35.1677 - acc: 0.1497\n",
      "Epoch 96/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 21.1055 - acc: 0.1633\n",
      "Epoch 97/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 19.9265 - acc: 0.1604\n",
      "Epoch 98/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 19.3367 - acc: 0.1520\n",
      "Epoch 99/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 16.3812 - acc: 0.1607\n",
      "Epoch 100/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 19.0547 - acc: 0.1568\n",
      "Epoch 101/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 17.3613 - acc: 0.1512\n",
      "Epoch 102/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 21.0367 - acc: 0.1693\n",
      "Epoch 103/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 19.3259 - acc: 0.1635\n",
      "Epoch 104/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 21.2272 - acc: 0.1640\n",
      "Epoch 105/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 20.5496 - acc: 0.1633\n",
      "Epoch 106/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 39.9951 - acc: 0.1498\n",
      "Epoch 107/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 18.1443 - acc: 0.1732\n",
      "Epoch 108/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 28.4068 - acc: 0.1609\n",
      "Epoch 109/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 15.5751 - acc: 0.1609\n",
      "Epoch 110/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 22.0705 - acc: 0.1578\n",
      "Epoch 111/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 22.6018 - acc: 0.1669\n",
      "Epoch 112/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 17.2386 - acc: 0.1691\n",
      "Epoch 113/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 15.4205 - acc: 0.1807\n",
      "Epoch 114/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 19.2077 - acc: 0.1627\n",
      "Epoch 115/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 24.2752 - acc: 0.1567\n",
      "Epoch 116/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 21.7468 - acc: 0.1619\n",
      "Epoch 117/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 17.5942 - acc: 0.1867\n",
      "Epoch 118/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 20.1762 - acc: 0.1683\n",
      "Epoch 119/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 21.1531 - acc: 0.1693\n",
      "Epoch 120/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 31.5090 - acc: 0.1540\n",
      "Epoch 121/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 22.1436 - acc: 0.1601\n",
      "Epoch 122/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 19.6873 - acc: 0.1620\n",
      "Epoch 123/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 16.6374 - acc: 0.1831\n",
      "Epoch 124/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.9533 - acc: 0.1759\n",
      "Epoch 125/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 19.3292 - acc: 0.1697\n",
      "Epoch 126/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 20.4698 - acc: 0.1787\n",
      "Epoch 127/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 16.7048 - acc: 0.1843\n",
      "Epoch 128/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 21.4046 - acc: 0.1700\n",
      "Epoch 129/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 29.1285 - acc: 0.1696\n",
      "Epoch 130/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 16.1796 - acc: 0.1834\n",
      "Epoch 131/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 17.2141 - acc: 0.1670\n",
      "Epoch 132/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 11.0530 - acc: 0.1901\n",
      "Epoch 133/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 18.7234 - acc: 0.1626\n",
      "Epoch 134/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 26.1098 - acc: 0.1665\n",
      "Epoch 135/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 19.8220 - acc: 0.1791\n",
      "Epoch 136/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.9737 - acc: 0.1917\n",
      "Epoch 137/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 16.3580 - acc: 0.1892\n",
      "Epoch 138/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 16.6768 - acc: 0.1918\n",
      "Epoch 139/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 17.3121 - acc: 0.1850\n",
      "Epoch 140/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.9318 - acc: 0.1925\n",
      "Epoch 141/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 14.9570 - acc: 0.1881\n",
      "Epoch 142/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 21.0979 - acc: 0.1828\n",
      "Epoch 143/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 20.8776 - acc: 0.1792\n",
      "Epoch 144/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.2630 - acc: 0.1870\n",
      "Epoch 145/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 14.0494 - acc: 0.1973\n",
      "Epoch 146/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 17.2424 - acc: 0.1881\n",
      "Epoch 147/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.5849 - acc: 0.1890\n",
      "Epoch 148/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.4607 - acc: 0.2077\n",
      "Epoch 149/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.1567 - acc: 0.1962\n",
      "Epoch 150/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 18.4235 - acc: 0.1821\n",
      "Epoch 151/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 15.9335 - acc: 0.1768\n",
      "Epoch 152/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 18.5596 - acc: 0.1745\n",
      "Epoch 153/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.8678 - acc: 0.1979\n",
      "Epoch 154/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.0159 - acc: 0.2132\n",
      "Epoch 155/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.3718 - acc: 0.2075\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10067/10067 [==============================] - 41s 4ms/step - loss: 17.2432 - acc: 0.2102\n",
      "Epoch 157/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.0716 - acc: 0.1956\n",
      "Epoch 158/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 10.2239 - acc: 0.2096\n",
      "Epoch 159/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 10.3030 - acc: 0.2024\n",
      "Epoch 160/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 15.1667 - acc: 0.1971\n",
      "Epoch 161/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 15.0495 - acc: 0.2034\n",
      "Epoch 162/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 12.9683 - acc: 0.2057\n",
      "Epoch 163/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.0010 - acc: 0.2168\n",
      "Epoch 164/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 10.3228 - acc: 0.2206\n",
      "Epoch 165/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.4695 - acc: 0.2010\n",
      "Epoch 166/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 15.5006 - acc: 0.2096\n",
      "Epoch 167/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.0179 - acc: 0.2110\n",
      "Epoch 168/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 9.5709 - acc: 0.2279\n",
      "Epoch 169/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.9965 - acc: 0.2140\n",
      "Epoch 170/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 13.1026 - acc: 0.2056\n",
      "Epoch 171/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.1422 - acc: 0.2059\n",
      "Epoch 172/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.3690 - acc: 0.2267\n",
      "Epoch 173/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.7719 - acc: 0.2146\n",
      "Epoch 174/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.9560 - acc: 0.2090\n",
      "Epoch 175/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 10.3304 - acc: 0.2202\n",
      "Epoch 176/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 10.8486 - acc: 0.2203\n",
      "Epoch 177/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 10.5466 - acc: 0.2123\n",
      "Epoch 178/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.5744 - acc: 0.2136\n",
      "Epoch 179/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.2454 - acc: 0.2159\n",
      "Epoch 180/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 14.3239 - acc: 0.2020\n",
      "Epoch 181/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.2932 - acc: 0.2222\n",
      "Epoch 182/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 13.1379 - acc: 0.2249\n",
      "Epoch 183/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.0056 - acc: 0.2271\n",
      "Epoch 184/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.4074 - acc: 0.2321\n",
      "Epoch 185/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 42.8218 - acc: 0.1882\n",
      "Epoch 186/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 15.2064 - acc: 0.1968\n",
      "Epoch 187/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 7.8533 - acc: 0.2347\n",
      "Epoch 188/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 14.0978 - acc: 0.2106\n",
      "Epoch 189/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 17.8985 - acc: 0.2131\n",
      "Epoch 190/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.1393 - acc: 0.2353\n",
      "Epoch 191/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 9.2777 - acc: 0.2324\n",
      "Epoch 192/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 9.8577 - acc: 0.2374\n",
      "Epoch 193/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 10.6981 - acc: 0.2097\n",
      "Epoch 194/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 8.4085 - acc: 0.2333\n",
      "Epoch 195/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.7683 - acc: 0.2225\n",
      "Epoch 196/200\n",
      "10067/10067 [==============================] - 41s 4ms/step - loss: 11.5702 - acc: 0.2212\n",
      "Epoch 197/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 11.9129 - acc: 0.2180\n",
      "Epoch 198/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 8.7318 - acc: 0.2336\n",
      "Epoch 199/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 12.6682 - acc: 0.2369\n",
      "Epoch 200/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 6.5634 - acc: 0.2444\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "#opt = RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "opt = Adam(lr=0.002, epsilon=None, decay=0.0)\n",
    "model.compile(loss=\"mse\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "# logcosh, mes, \n",
    "H = model.fit([train_img,train_wea], train_val ,batch_size=10, epochs=200)\n",
    "\n",
    "\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save('new-ultra-LSTM-adam-9:10.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11186, 250, 350, 3)\n",
      "(11186,)\n",
      "(11186,)\n",
      "(11186,)\n",
      "(1119, 250, 350, 3)\n",
      "(1119, 2)\n",
      "[[3.4842286]\n",
      " [1.9748597]\n",
      " [2.7918177]\n",
      " ...\n",
      " [4.307754 ]\n",
      " [4.3870277]\n",
      " [4.3554454]]\n",
      "(1119,)\n",
      "(1119,)\n",
      "[3 2 2 ... 3 3 3]\n",
      "[3 1 2 ... 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(image_arr.shape)\n",
    "print(dust_arr.shape)\n",
    "\n",
    "print(wind_arr.shape)\n",
    "print(humi_arr.shape)\n",
    "\n",
    "print(test_img.shape)\n",
    "print(test_wea.shape)\n",
    "\n",
    "print(model.predict([test_img, test_wea]))\n",
    "\n",
    "y_pred = np.squeeze(np.round(model.predict([test_img, test_wea]).astype(np.int64)))\n",
    "\n",
    "print(test_val.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "print(np.round(test_val.astype(np.int64)))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 는 :  18.40573889599158\n",
      "R2SCORE 는 :  -0.027688047121706694\n"
     ]
    }
   ],
   "source": [
    "RMSE = mean_squared_error(test_val.astype(np.int64), y_pred)**0.5\n",
    "R2SCORE = r2_score(test_val.astype(np.int64), y_pred)\n",
    "\n",
    "print(\"RMSE 는 : \" , RMSE)\n",
    "print(\"R2SCORE 는 : \", R2SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(70, 50, 'R-squared = -0.03')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_val=np.squeeze(test_val.astype(np.int64))\n",
    "\n",
    "plt.scatter(test_val,y_pred)\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "\n",
    "plt.plot(np.unique(test_val), np.poly1d(np.polyfit(test_val, y_pred, 1))(np.unique(test_val)))\n",
    "\n",
    "plt.text(70, 50, 'R-squared = %0.2f' % R2SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(test_val.astype(np.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, ..., 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
