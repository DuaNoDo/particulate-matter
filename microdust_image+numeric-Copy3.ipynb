{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from PIL import Image\n",
    "from imutils import paths\n",
    "from os import path\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "import pandas as pd\n",
    "keras.__version__\n",
    "IMAGE_DIMS = (350,250,3)\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_arr = np.load('./new_date_arr.npy',allow_pickle=True)\n",
    "dust_arr = np.load('./result_arr_avg_7.npy',allow_pickle=True)\n",
    "wind_arr = np.load('./wind_arr.npy',allow_pickle=True)\n",
    "humi_arr = np.load('./humi_arr.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 18126 images (22940.04MB)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time() \n",
    "imagePaths = sorted(list(paths.list_images('./dataset/image')))\n",
    "image_arr = []\n",
    "\n",
    "for i in imagePaths:\n",
    "    img_name = int(path.splitext(path.basename(i))[0])\n",
    "    \n",
    "    if img_name in date_arr :\n",
    "        image = Image.open(i)\n",
    "        image = image.resize((IMAGE_DIMS[0],IMAGE_DIMS[1]))\n",
    "        image = img_to_array(image)\n",
    "        image_arr.append(image)\n",
    "        \n",
    "image_arr = np.array(image_arr, dtype=\"float\") / 255.0        \n",
    "print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(len(imagePaths), image_arr.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11186,)\n",
      "(11186, 250, 350, 3)\n",
      "(10067, 250, 350, 3)\n",
      "(1119, 250, 350, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "con_data_img = image_arr\n",
    "con_data_val = dust_arr\n",
    "\n",
    "print(wind_arr.shape)\n",
    "con_data_wea = np.concatenate([wind_arr.reshape(len(wind_arr),1),humi_arr.reshape(len(humi_arr),1)], axis=1)\n",
    "\n",
    "\n",
    "# 국내는 PM2.5이 16이상이면 보통\n",
    "# for i in range(0,dustvalue.shape[0]):\n",
    "#     if int(dustvalue[i]) > 0 :\n",
    "#         con_data_img.append(data[i])\n",
    "#         con_data_val.append(dustvalue[i])\n",
    "#         con_data_wea.append(add_info[i])\n",
    "        \n",
    "# con_data_img, con_data_val, con_data_wea = shuffle(np.array(con_data_img), np.array(con_data_val), np.array(con_data_wea), random_state=0)\n",
    "# con_data_img = np.array(con_data_img)\n",
    "# con_data_val = np.array(con_data_val)\n",
    "# con_data_wea = np.array(con_data_wea)\n",
    "\n",
    "num = int(con_data_img.shape[0]*0.9)\n",
    "\n",
    "train_img = con_data_img[:num]\n",
    "train_val = con_data_val[:num]\n",
    "train_wea = con_data_wea[:num]\n",
    "\n",
    "test_img = con_data_img[num:]\n",
    "test_val = con_data_val[num:]\n",
    "test_wea = con_data_wea[num:]\n",
    "\n",
    "print(con_data_img.shape)\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, LSTM, GRU, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "chanDim=-1\n",
    "model = Sequential()\n",
    "\n",
    "# CONV => RELU => POOL\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(IMAGE_DIMS[1], IMAGE_DIMS[0],3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "image_input = Input(shape=(IMAGE_DIMS[1], IMAGE_DIMS[0],3))\n",
    "encoded_image = model(image_input)\n",
    "\n",
    "# 다음은 문제를 벡터로 인코딩할 숫자 모델을 정의합니다\n",
    "numeric_input = Input(shape=(2,))\n",
    "embedded_numeric = Embedding(input_dim=100, output_dim=256, input_length=2)(numeric_input)\n",
    "\n",
    "# numeric_input2 = Dense(256, activation=\"linear\")(embedded_numeric)\n",
    "# print(embedded_numeric.shape)\n",
    "\n",
    "#numeric_input2 = GRU(256)(embedded_numeric)\n",
    "numeric_input2 = GRU(256)(embedded_numeric)\n",
    "# print(numeric_input2.shape)\n",
    "\n",
    "\n",
    "# numeric_input = Input(shape=(8,), dtype='float32')\n",
    "# numeric_input1 = Dense(1000,activation='linear')(numeric_input)\n",
    "# numeric_input2 = Dense(100,activation='linear')(numeric_input1)\n",
    "\n",
    "# 질문 벡터와 이미지 벡터를 연결해 봅시다:\n",
    "merged = keras.layers.concatenate([encoded_image, numeric_input2],axis=-1)\n",
    "\n",
    "output = Dense(1)(merged)\n",
    "\n",
    "# 그리고 상층의 로지스틱 회귀를 수치에 대해 학습시킵니다:\n",
    "# output = Dense(1024, activation='softmax')(merged)\n",
    "# output = Dense(128, activation='softmax')(output)\n",
    "# output = Dense(1)(output)\n",
    "# 다음은 최종 모델입니다:\n",
    "model = Model(inputs=[image_input, numeric_input], outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "10067/10067 [==============================] - 40s 4ms/step - loss: 431.3046 - acc: 0.0064\n",
      "Epoch 2/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 348.1464 - acc: 0.0080\n",
      "Epoch 3/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 302.3650 - acc: 0.0097\n",
      "Epoch 4/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 278.5802 - acc: 0.0099\n",
      "Epoch 5/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 260.5095 - acc: 0.0085\n",
      "Epoch 6/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 248.8133 - acc: 0.0104\n",
      "Epoch 7/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 219.6372 - acc: 0.0092\n",
      "Epoch 8/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 209.1199 - acc: 0.0099\n",
      "Epoch 9/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 192.8970 - acc: 0.0114\n",
      "Epoch 10/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 178.0724 - acc: 0.0102\n",
      "Epoch 11/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 168.2165 - acc: 0.0117\n",
      "Epoch 12/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 154.7823 - acc: 0.0111\n",
      "Epoch 13/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 130.3494 - acc: 0.0128\n",
      "Epoch 14/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 140.3102 - acc: 0.0083\n",
      "Epoch 15/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 108.1018 - acc: 0.0107\n",
      "Epoch 16/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 104.7033 - acc: 0.0107\n",
      "Epoch 17/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 112.3340 - acc: 0.0120\n",
      "Epoch 18/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 81.8567 - acc: 0.0107\n",
      "Epoch 19/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 78.5575 - acc: 0.0122\n",
      "Epoch 20/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 73.2148 - acc: 0.0138\n",
      "Epoch 21/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 79.6070 - acc: 0.0133\n",
      "Epoch 22/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 69.5188 - acc: 0.0133\n",
      "Epoch 23/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 75.1349 - acc: 0.0145\n",
      "Epoch 24/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 68.4168 - acc: 0.0138\n",
      "Epoch 25/200\n",
      "10067/10067 [==============================] - 39s 4ms/step - loss: 81.2902 - acc: 0.0123\n",
      "Epoch 26/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 57.0973 - acc: 0.0144\n",
      "Epoch 27/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 46.6336 - acc: 0.0179\n",
      "Epoch 28/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 41.1739 - acc: 0.0193\n",
      "Epoch 29/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 34.7859 - acc: 0.0169\n",
      "Epoch 30/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 37.0495 - acc: 0.0176\n",
      "Epoch 31/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 58.0959 - acc: 0.0160\n",
      "Epoch 32/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 32.2442 - acc: 0.0200\n",
      "Epoch 33/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 41.8249 - acc: 0.0157\n",
      "Epoch 34/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 52.8163 - acc: 0.0154\n",
      "Epoch 35/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 48.0109 - acc: 0.0164\n",
      "Epoch 36/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 26.9058 - acc: 0.0189\n",
      "Epoch 37/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 25.9744 - acc: 0.0206\n",
      "Epoch 38/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 26.0685 - acc: 0.0195\n",
      "Epoch 39/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 61.6515 - acc: 0.0155\n",
      "Epoch 40/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 31.5968 - acc: 0.0179\n",
      "Epoch 41/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 27.7129 - acc: 0.0215\n",
      "Epoch 42/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 27.1400 - acc: 0.0218\n",
      "Epoch 43/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 50.5139 - acc: 0.0155\n",
      "Epoch 44/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 36.7445 - acc: 0.0165\n",
      "Epoch 45/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 22.8347 - acc: 0.0187\n",
      "Epoch 46/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 64.1809 - acc: 0.0157\n",
      "Epoch 47/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 26.9942 - acc: 0.0190\n",
      "Epoch 48/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 21.6152 - acc: 0.0190\n",
      "Epoch 49/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 23.9399 - acc: 0.0187\n",
      "Epoch 50/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 18.2331 - acc: 0.0226\n",
      "Epoch 51/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 17.9894 - acc: 0.0233\n",
      "Epoch 52/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 18.8717 - acc: 0.0216\n",
      "Epoch 53/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 19.7200 - acc: 0.0197\n",
      "Epoch 54/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 21.6953 - acc: 0.0219\n",
      "Epoch 55/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 16.3975 - acc: 0.0240\n",
      "Epoch 56/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 20.4876 - acc: 0.0245\n",
      "Epoch 57/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 23.4781 - acc: 0.0238\n",
      "Epoch 58/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 15.5588 - acc: 0.0235\n",
      "Epoch 59/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 62.2245 - acc: 0.0174\n",
      "Epoch 60/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 45.5920 - acc: 0.0156\n",
      "Epoch 61/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 50.2288 - acc: 0.0176\n",
      "Epoch 62/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 28.4988 - acc: 0.0188\n",
      "Epoch 63/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 23.5590 - acc: 0.0216\n",
      "Epoch 64/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 20.0655 - acc: 0.0242\n",
      "Epoch 65/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 19.5233 - acc: 0.0248\n",
      "Epoch 66/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 15.7788 - acc: 0.0213\n",
      "Epoch 67/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 20.8955 - acc: 0.0210\n",
      "Epoch 68/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 19.5518 - acc: 0.0243\n",
      "Epoch 69/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 35.1503 - acc: 0.0199\n",
      "Epoch 70/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 15.0734 - acc: 0.0220\n",
      "Epoch 71/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 23.5040 - acc: 0.0227\n",
      "Epoch 72/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 22.5761 - acc: 0.0240\n",
      "Epoch 73/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 29.4779 - acc: 0.0223\n",
      "Epoch 74/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 33.3472 - acc: 0.0216\n",
      "Epoch 75/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 25.9159 - acc: 0.0200\n",
      "Epoch 76/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 18.1751 - acc: 0.0224\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10067/10067 [==============================] - 37s 4ms/step - loss: 18.0366 - acc: 0.0234\n",
      "Epoch 78/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 17.5316 - acc: 0.0241\n",
      "Epoch 79/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 13.9412 - acc: 0.0234\n",
      "Epoch 80/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 31.2150 - acc: 0.0220\n",
      "Epoch 81/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 14.0711 - acc: 0.0253\n",
      "Epoch 82/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 11.4686 - acc: 0.0267\n",
      "Epoch 83/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 13.1697 - acc: 0.0266\n",
      "Epoch 84/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 13.1150 - acc: 0.0247\n",
      "Epoch 85/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 17.4164 - acc: 0.0254\n",
      "Epoch 86/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 14.5131 - acc: 0.0240\n",
      "Epoch 87/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 13.6394 - acc: 0.0257\n",
      "Epoch 88/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 11.5256 - acc: 0.0276\n",
      "Epoch 89/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 12.4664 - acc: 0.0263\n",
      "Epoch 90/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 10.8891 - acc: 0.0273\n",
      "Epoch 91/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 12.0072 - acc: 0.0247\n",
      "Epoch 92/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 11.7527 - acc: 0.0284\n",
      "Epoch 93/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 9.4965 - acc: 0.0288\n",
      "Epoch 94/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 14.0396 - acc: 0.0236\n",
      "Epoch 95/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 19.9592 - acc: 0.0236\n",
      "Epoch 96/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 15.0183 - acc: 0.0280\n",
      "Epoch 97/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 8.8994 - acc: 0.0287\n",
      "Epoch 98/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 9.4955 - acc: 0.0304\n",
      "Epoch 99/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 10.0117 - acc: 0.0305\n",
      "Epoch 100/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 10.9651 - acc: 0.0296\n",
      "Epoch 101/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 11.5467 - acc: 0.0301\n",
      "Epoch 102/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 8.9286 - acc: 0.0302\n",
      "Epoch 103/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 9.6648 - acc: 0.0284\n",
      "Epoch 104/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 9.9325 - acc: 0.0317\n",
      "Epoch 105/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 36.3106 - acc: 0.0262\n",
      "Epoch 106/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 14.5268 - acc: 0.0264\n",
      "Epoch 107/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 22.1524 - acc: 0.0293\n",
      "Epoch 108/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 30.3123 - acc: 0.0227\n",
      "Epoch 109/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 13.4614 - acc: 0.0279\n",
      "Epoch 110/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 11.8093 - acc: 0.0297\n",
      "Epoch 111/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 13.3362 - acc: 0.0252\n",
      "Epoch 112/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 12.2313 - acc: 0.0278\n",
      "Epoch 113/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 21.8912 - acc: 0.0249\n",
      "Epoch 114/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 17.8546 - acc: 0.0274\n",
      "Epoch 115/200\n",
      "10067/10067 [==============================] - 38s 4ms/step - loss: 32.8892 - acc: 0.0207\n",
      "Epoch 116/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 23.1540 - acc: 0.0226\n",
      "Epoch 117/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 21.2137 - acc: 0.0236\n",
      "Epoch 118/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 39.1614 - acc: 0.0215\n",
      "Epoch 119/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 32.7425 - acc: 0.0201\n",
      "Epoch 120/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 20.1294 - acc: 0.0230\n",
      "Epoch 121/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 15.4404 - acc: 0.0251\n",
      "Epoch 122/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 17.2532 - acc: 0.0241\n",
      "Epoch 123/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 15.0193 - acc: 0.0273\n",
      "Epoch 124/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 13.9088 - acc: 0.0253\n",
      "Epoch 125/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 18.8136 - acc: 0.0257\n",
      "Epoch 126/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 9.7092 - acc: 0.0286\n",
      "Epoch 127/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 18.8719 - acc: 0.0252\n",
      "Epoch 128/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 22.2518 - acc: 0.0208\n",
      "Epoch 129/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 15.9798 - acc: 0.0224\n",
      "Epoch 130/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 11.7232 - acc: 0.0250\n",
      "Epoch 131/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 16.8191 - acc: 0.0222\n",
      "Epoch 132/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 17.7019 - acc: 0.0237\n",
      "Epoch 133/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 16.1798 - acc: 0.0246\n",
      "Epoch 134/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 10.2760 - acc: 0.0277\n",
      "Epoch 135/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.4800 - acc: 0.0297\n",
      "Epoch 136/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 9.2106 - acc: 0.0307\n",
      "Epoch 137/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 11.4924 - acc: 0.0265\n",
      "Epoch 138/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 18.5369 - acc: 0.0248\n",
      "Epoch 139/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 19.0140 - acc: 0.0260\n",
      "Epoch 140/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 12.3397 - acc: 0.0263\n",
      "Epoch 141/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 12.9447 - acc: 0.0282\n",
      "Epoch 142/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 11.8035 - acc: 0.0286\n",
      "Epoch 143/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 15.7943 - acc: 0.0306\n",
      "Epoch 144/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 10.1617 - acc: 0.0285\n",
      "Epoch 145/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 9.0534 - acc: 0.0310\n",
      "Epoch 146/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 12.6178 - acc: 0.0300\n",
      "Epoch 147/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 12.9062 - acc: 0.0278\n",
      "Epoch 148/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 15.4231 - acc: 0.0266\n",
      "Epoch 149/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 11.8059 - acc: 0.0263\n",
      "Epoch 150/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 19.2014 - acc: 0.0276\n",
      "Epoch 151/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 13.0258 - acc: 0.0250\n",
      "Epoch 152/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.7547 - acc: 0.0301\n",
      "Epoch 153/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.0035 - acc: 0.0310\n",
      "Epoch 154/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 10.4404 - acc: 0.0269\n",
      "Epoch 155/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 10.8927 - acc: 0.0281\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10067/10067 [==============================] - 37s 4ms/step - loss: 9.5296 - acc: 0.0306\n",
      "Epoch 157/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 13.6474 - acc: 0.0286\n",
      "Epoch 158/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.8891 - acc: 0.0322\n",
      "Epoch 159/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 13.7660 - acc: 0.0269\n",
      "Epoch 160/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.8257 - acc: 0.0317\n",
      "Epoch 161/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 6.3801 - acc: 0.0317\n",
      "Epoch 162/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 14.0954 - acc: 0.0296\n",
      "Epoch 163/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 11.1349 - acc: 0.0292\n",
      "Epoch 164/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 14.5691 - acc: 0.0286\n",
      "Epoch 165/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 11.0849 - acc: 0.0294\n",
      "Epoch 166/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.0934 - acc: 0.0314\n",
      "Epoch 167/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.4592 - acc: 0.0353\n",
      "Epoch 168/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 9.1174 - acc: 0.0314\n",
      "Epoch 169/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 17.9201 - acc: 0.0283\n",
      "Epoch 170/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 12.1751 - acc: 0.0271\n",
      "Epoch 171/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 12.6638 - acc: 0.0325\n",
      "Epoch 172/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 10.2026 - acc: 0.0310\n",
      "Epoch 173/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.8442 - acc: 0.0299\n",
      "Epoch 174/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.0559 - acc: 0.0327\n",
      "Epoch 175/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 9.3976 - acc: 0.0314\n",
      "Epoch 176/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.6048 - acc: 0.0309\n",
      "Epoch 177/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.1059 - acc: 0.0304\n",
      "Epoch 178/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 12.8256 - acc: 0.0311\n",
      "Epoch 179/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.0344 - acc: 0.0344\n",
      "Epoch 180/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 6.4613 - acc: 0.0311\n",
      "Epoch 181/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.3594 - acc: 0.0355\n",
      "Epoch 182/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.4055 - acc: 0.0337\n",
      "Epoch 183/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.7368 - acc: 0.0364\n",
      "Epoch 184/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.1738 - acc: 0.0351\n",
      "Epoch 185/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 11.8277 - acc: 0.0332\n",
      "Epoch 186/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 10.8034 - acc: 0.0351\n",
      "Epoch 187/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 9.8290 - acc: 0.0331\n",
      "Epoch 188/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.5100 - acc: 0.0330\n",
      "Epoch 189/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.0094 - acc: 0.0358\n",
      "Epoch 190/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 10.6403 - acc: 0.0330\n",
      "Epoch 191/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.6529 - acc: 0.0322\n",
      "Epoch 192/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.1428 - acc: 0.0375\n",
      "Epoch 193/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.9927 - acc: 0.0385\n",
      "Epoch 194/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 8.1569 - acc: 0.0338\n",
      "Epoch 195/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 6.4985 - acc: 0.0368\n",
      "Epoch 196/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.9957 - acc: 0.0325\n",
      "Epoch 197/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.3706 - acc: 0.0355\n",
      "Epoch 198/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 5.8336 - acc: 0.0343\n",
      "Epoch 199/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 11.5132 - acc: 0.0338\n",
      "Epoch 200/200\n",
      "10067/10067 [==============================] - 37s 4ms/step - loss: 7.2631 - acc: 0.0383\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "#opt = RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "opt = Adam(lr=0.002, epsilon=None, decay=0.0)\n",
    "model.compile(loss=\"mse\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "# logcosh, mes, \n",
    "H = model.fit([train_img,train_wea], train_val ,batch_size=10, epochs=200)\n",
    "\n",
    "\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save('new-LSTM-adam-9:10.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11186, 250, 350, 3)\n",
      "(11186,)\n",
      "(11186,)\n",
      "(11186,)\n",
      "(1119, 250, 350, 3)\n",
      "(1119, 2)\n",
      "[[5.2976484]\n",
      " [2.0509484]\n",
      " [4.722969 ]\n",
      " ...\n",
      " [7.5381927]\n",
      " [7.1902294]\n",
      " [7.322706 ]]\n",
      "(1119,)\n",
      "(1119,)\n",
      "[3 4 4 ... 3 4 4]\n",
      "[5 2 4 ... 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "print(image_arr.shape)\n",
    "print(dust_arr.shape)\n",
    "\n",
    "print(wind_arr.shape)\n",
    "print(humi_arr.shape)\n",
    "\n",
    "print(test_img.shape)\n",
    "print(test_wea.shape)\n",
    "\n",
    "print(model.predict([test_img, test_wea]))\n",
    "\n",
    "y_pred = np.squeeze(np.round(model.predict([test_img, test_wea]).astype(np.int64)))\n",
    "\n",
    "print(test_val.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "print(np.round(test_val.astype(np.int64)))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 는 :  18.275128989665674\n",
      "R2SCORE 는 :  -0.025756086347468843\n"
     ]
    }
   ],
   "source": [
    "RMSE = mean_squared_error(test_val.astype(np.int64), y_pred)**0.5\n",
    "R2SCORE = r2_score(test_val.astype(np.int64), y_pred)\n",
    "\n",
    "print(\"RMSE 는 : \" , RMSE)\n",
    "print(\"R2SCORE 는 : \", R2SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(70, 50, 'R-squared = -0.03')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAHKCAYAAAAEgSCfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3df7wddX3n8dcnNzfJTUi4CSQIl4RAzKKW8DMV2NgWdSlIrcafJQtbu3XBdXWtVbFEqD+2ulJRW6utWxSFKotafkS0VqQidaUSTfgVFKKACASEaH5AycXc3Hz2j5mTzD135pyZc2fOr+/7+Xjkce+ZM2fmeyb3fs7cmfd8xtwdEREJx7ROD0BERNpLhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFRAKjwi+Sk5mNm9mdZnaPmX3NzIY7PaYizOwKM3ttycucaWZfNrP7zWy9mS3NmO9MM9scz3dhYvrlZnaXmd1tZteY2QFljk/SqfCL5Dfq7se7+zHANuAtnR6QmU3v8BDeCGx39+cCfwX8Zf0MZjYA/C3wMuAFwBoze0H89J+6+3HufizwMPDW9gw7bCr8Iq35PjCS9oSZvS7+q+AuM/tuPG3IzL4U79l+Od47Xhk/9++J177WzK6Iv//9eL47zOxfzOyQePr7zewyM/sW8A9mNmBml5rZD+Plvymez8zsU2b2YzP7J2BRBdvhlcCV8ffXAC81M6ub54XA/e7+oLvvBr4Uvw53f6o2VmAI0BWlbdDpvQWRnhPvwb4UuDxjlvcCZ7j7lsThoDcDu9z9WDM7Frg9x6q+B5zi7m5m/w14N/DO+LmTgBe5+6iZnQ/sdPffNLOZwK3xh8IJwNHACuAQ4MfA51LezwXAOSnr/667v63JGEeARwDcfY+Z7QQOAn6ZNk/sUeDkxPo/D5wVj++dSOVU+EXyGzKzO4GlwEbgpoz5bgWuMLOvANfF034b+BsAd7/bzO7Osb7DgS+b2aHADOBnieducPfR+PvfBY5NHL8/EFger/Nqdx8HHjOzm9NW4u6XApfmGE+a+r17mLzX3nAed/+v8YfpJ4E/AD7f4lgkJx3qEclv1N2PB44gKsRvATCzD8Unfe8EcPf/DlwMLAbuNLOD4tdnHcZITp+V+P6TwKfcfQXwprrnnkl8b8D/jM8/HO/uR7r7t5qsc/+LzS6ojb/u39+kzDvhvRLtvS+On5tO9KGzre5l++aJHQ48lpwh/nD6MvCaZuOVqVPhFynI3XcCbwPeZWaD7n5RregCmNkyd1/v7u8lOuSxGPgu8eEUMzsGODaxyCfM7PlmNg14VWL6gcCW+Ps3NBjSjcCbzWwwXv5/MLM58TrPjs8BHAq8OOP9XJr40Ej+m3SYp/69AjckxvZa4Gaf3Pnxh8ByMzvSzGYAZwM3xOcgnhuP2YDfB+5r8D6lJDrUI9ICd7/DzO4iKmJfqHv6UjNbTrQn/m3gLmAz8Pn4EM+dwA8S818IfJ3oOPg9QC3S+H7gH81sC3AbcGTGcD5LdPjp9riAbgVWA9cDLwE2AT8B/rXFt9vI5cAXzOx+oj39swHM7DDgs+5+Vnzs/61EH1ADwOfc/UfxB92VZjaPaFvdRXQuRCpmasss0n5mdgvwLnff0OmxSHh0qEdEJDDa4xcRCYz2+EVEAqPCLyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFRAKjwi8iEhgVfhGRwKjwi4gERoVfRCQwKvwiIoFR4RcRCYwKv4hIYFT4RUQCo8IvIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBUeEXEQmMCr+ISGBU+EVEAqPCLyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFRAKjwi8iEhgVfhGRwKjwi4gERoVfRCQwKvwiIoFR4RcRCYwKv4hIYFT4RUQCo8IvIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBUeEXEQmMCr+ISGBU+EVEAqPCLyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFRAKjwi8iEhgVfhGRwKjwi4gERoVfRCQwKvwiIoFR4RcRCYwKv4hIYFT4RUQCo8IvIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBUeEXEQmMCr+ISGBU+EVEAqPCLyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFRAKjwi8iEhgVfhGRwKjwi4gERoVfRCQwKvwiIoFR4RcRCYwKv4hIYFT4RUQCo8IvIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBUeEXEQmMCr+ISGBU+EVEAqPCLyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFRAKjwi8iEhgVfhGRwKjwi4gERoVfRCQwKvwiIoFR4RcRCYwKv4hIYFT4RUQCo8IvIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBUeEXEQmMCr+ISGBU+EVEAqPCLyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFRAKjwi8iEhgVfhGRwKjwi4gERoVfRCQwKvwiIoFR4RcRCYwKv4hIYFT4RUQCo8IvIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBUeEXEQmMCr+ISGBU+EVEAqPCLyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFRAKjwi8iEhgVfhGRwKjwi4gERoVfRCQwKvwiIoFR4RcRCYwKv4hIYFT4RUQCo8IvIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBUeEXEQmMCr+ISGBU+EVEAqPCLyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFRAKjwi8iEhgVfhGRwKjwi4gERoVfRCQwKvwiIoFR4RcRCYwKv4hIYKZ3egB5HHzwwb506dJOD0NEpKds3Ljxl+6+sH56TxT+pUuXsmHDhk4PQ0Skp5jZz9Om61CPiEhgVPhFRAKjwi8iEhgVfhGRwKjwi4gEprLCb2aLzew7Znavmf3IzP4knv5+M9tiZnfG/86qagxJ6+7YwqpLbubIC/+JVZfczLo7trRjtSIiXafKOOce4J3ufruZzQU2mtlN8XN/5e4frXDdE6y7Ywtrr9vE6Ng4AFt2jLL2uk0ArD5hpF3DEBHpCpXt8bv74+5+e/z908C9QEeq7KU3bt5X9GtGx8a59MbNnRiOiEhHteUYv5ktBU4A1seT3mpmd5vZ58xsfsZrzjezDWa2YevWrVNa/2M7RgtNFxHpZ5UXfjM7ALgWeLu7PwV8GlgGHA88Dnws7XXufpm7r3T3lQsXTrriuJDDhocKTRcR6WeVFn4zGyQq+le5+3UA7v6Eu4+7+17gM8ALqxwDwAVnHM3Q4MCEaUODA1xwxtFVr1pEpOtUdnLXzAy4HLjX3T+emH6ouz8eP3wVcE9VY6ipncC99MbNPLZjlMOGh7jgjKN1YldEglRlqmcV8F+ATWZ2ZzztPcAaMzsecOAh4E0VjmGf1SeMqNCLiFBh4Xf37wGW8tQ3qlqniIg0pyt3RUQCo8IvIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBUeEXEQmMCr+ISGBU+EVEAqPCLyISGBV+EZHAqPCLiARGhV9EJDAq/CIigVHhFxEJjAq/iEhgVPhFRAKjwi8iEhgVfhGRwKjwi4gERoVfRCQwKvwiIoFR4RcRCYwKv4hIYFT4RUQCo8IvIhIYFX4RkcCo8IuIBEaFX0QkMCr8IiKBqazwm9liM/uOmd1rZj8ysz+Jpy8ws5vM7Kfx1/lVjUFERCabXuGy9wDvdPfbzWwusNHMbgL+CPi2u19iZhcCFwJ/VuE4et7F6zZx9fpHGHdnwIw1Jy/mg6tXdHpYpVh3xxYuvXEzj+0Y5bDhIS4442hWnzDS6WGJ9LXK9vjd/XF3vz3+/mngXmAEeCVwZTzblcDqqsbQDy5et4kv3vYw4+4AjLvzxdse5uJ1mzo8sqlbd8cW1l63iS07RnFgy45R1l63iXV3bOn00ET6WluO8ZvZUuAEYD1wiLs/DtGHA7CoHWPoVVevf6TQ9F5y6Y2bGR0bnzBtdGycS2/c3KERiYSh8sJvZgcA1wJvd/enCrzufDPbYGYbtm7dWt0Au1xtTz/v9F7y2I7RQtNFpByVFn4zGyQq+le5+3Xx5CfM7ND4+UOBJ9Ne6+6XuftKd1+5cOHCKofZ1QbMCk3vJYcNDxWaLiLlqDLVY8DlwL3u/vHEUzcAb4i/fwPw1arG0A/WnLy40PRecsEZRzM0ODBh2tDgABeccXSHRiQShipTPauA/wJsMrM742nvAS4BvmJmbwQeBl5X4Rh6Xi2904+pnlp6R6kekfYy74FjxStXrvQNGzZ0ehgiIj3FzDa6+8r66VXu8UtJlHUXkTKp8He5Wta9FnusZd0BFX8RaYl69XQ5Zd1FpGwq/F1OWXcRKZsKf5dT1l1EyqbC3+WUdReRsunkbpdT1l1EyqbC3wNWnzCiQi8ipQmm8J/zme9z6wPb9j0enAZ79tJwDzqk/Hyn32un1y8SkiAKf33RBxjbG33NysWHlJ/v9Hvt9PpFQhPEyd36ol8vLRcfUn6+0++10+sXCU0QhT+P+lx8SPn5Tr/XTq9fJDQq/LH6XHxI+flOv9dOr18kNEEU/lXLFjR8Pi0XH1J+vtPvtdPrFwlN08JvZqvMbE78/blm9nEzO6L6oZXnqvNOnVT8B6eBASPDQ3z41SsmnURcfcIIH371CkaGhxrO1w86/V47vX6R0DTtx29mdwPHAccCXyC6q9ar3f13qh9eRP34RUSKm0o//j3u7mb2SuAT7n65mb2h6au6xOkfv4WfPvnMhGkjdTnxWoZ8y45RBsz23elq3H3CvEWy5hev21TaXbPSxlf/HkRE8spT+J82s7VEt1H8LTMbAAarHVY50oo+TMyJAxMy5OPxX0C1r7V5N/x8G9du3JIra37xuk188baH9z0ed9/3uGjxr8+4148rbf0iIo3kObn7B8CvgT92918AI8CllY6qJGlFv6aWE0/LkKfNe/X6R3Jnza9e/0jqcrKmN9JofMq6i0grmu7xu/svzOxaYHk86ZfA9ZWOqk2K5MTHM86FpC0ja96s6Y00G6Oy7iJSVJ5Uz3nANcDfx5NGgHVVDqpdDhseyp0VHzDLXEbeebOmN9JsfMq6i0hReQ71vAVYBTwF4O4/BRZVOaiyLF80J/O5Wk48LUOeNu+akxfnzpqvOXlx6nKypjfSaHzKuotIK/Kc3P21u++2eG/VzKYDxY9ZdMBN7zgtV6oHyJXqWXnEglypntoJ3DJSPcl+/Er1iEgZ8uT4PwLsAP4Q+J/A/wB+7O4XVT+8yFRy/GmxyvUP/mrSh0Gj+OaWuuPoq5Yt4KrzTgVabyesNsQTaXuIlC8rx5+n8E8D3gj8LtHFrjcCn/VmLyxRq4W/PlaZ19DgAK85aWRCfLPeqmULeN3KJROilrXXNrvqtD6imfd1/UrbQ6QaLRf+btBq4V+29hstJWlg/18AjYwMD036a6A2/dYLX5L5ulWX3NzS6/qVtodINVq+ctfMfkbKMX13P6qksVWm1aKf97WtthNWG+KJtD1E2ivPyd3kp8Us4HVA43aXXSLPXvtUXntYxh5/nghmK6/rV9oeIu3VNM7p7r9K/Nvi7n8N9MTf363EJyE7vpm0atmCltsJqw3xRNoeIu2V51DPiYmH04j+Aphb2YhKlBWrzJvqqcU3G6V6gMJplGREUykWbQ+RdsuT6vlO4uEe4CHgo+7etiYxasssIlJcyyd33f3FLa7wc8DLgSfd/Zh42vuB84Ct8WzvcfdvtLL8vJI5/pranv81P3yEZ8fznQNodGFXu+XJvPdKLr5XxinSTzILv5m9o9EL3f3jTZZ9BfAp4B/qpv+Vu3801+imKCvHn2yTnFdWu2Zob1vk+sx72jjyzNMNemWcIv2m0cnduU3+NeTu3wW2lTDGlrXSBrmITrRFTmvTXD+OPPN0g14Zp0i/ydzjd/cPVLTOt5rZHwIbgHe6+/a0mczsfOB8gCVLlrS0oqnk+PNqd9Y8T+a9V3LxvTJOkX6Tpy3zLDN7i5n9nZl9rvavxfV9GlgGHA88Dnwsa0Z3v8zdV7r7yoULF7a0slbaIBfV7qx51vqS0/PM0w16ZZwi/SZPW+YvAM8BzgD+FTgceLqVlbn7E+4+7u57gc8AL2xlOXm1muPPqxNZ8zyZ917JxffKOEX6TZ7C/1x3/3PgGXe/Evg9oKW7hpvZoYmHrwLuaWU5eX1w9QrOPWXJpD3/ATPOPWUJswby/0VQW0bt68jwUEeaiK0+YYQPv3oFI8NDWMY48szTDXplnCL9Jk+O/wfu/kIz+y5RS+ZfAD9o1qvHzK4GTgMOBp4A3hc/Pp6o989DwJvc/fFmg1SOX0SkuJZz/MBlZjYf+HPgBuCA+PuG3H1NyuTLc6yvVOd85vvc+kD+cFEyn1/fy/+Uo+bz0K9Gc+Xn62+asvSgIW57cHuhZdWrIvOeNd7ksvPMk3c9WWNPu29C1o1r6pf14uct5Dv3bdW1ACI55dnjH3D39Kb0bdLqHn/Rol8zNDjAiUsObPra+p7xaX3li6yz0WGOKnrWNxpvbdlA03nyfGA1GnvW9RbnnrJkUvHPs43Vy18kkrXHn+cY/8/M7DIze6lZG2IyJWql6EOUJc/z2jz5+SLrbJRfryLz3mi8tWXnmaeV9SRfm3W9Rdr0PNtY1wKINJan8B8N/AvRTdcfMrNPmdmLqh1W78iTn29lWXmfm8o689w3oNV7C+SZpzY963qLtOl536+uBRDJlqct86i7f8XdX010YnYeUaxTyJefb2VZeZ+byjrz3Dcgzzytrqc2Pet6i7Tped+vrgUQyZZnjx8z+x0z+zvgdqKbsby+0lGVZNWy1u4XMzQ4kOu1efLzRdbZKL9eRea90Xhry84zTyvrSb4263qLtOl5trGuBRBpLM+Vuz8D3g78P+AYd3+9u19b+chKcNV5pxYu/rUs+VXnnTrhGoABM1YtW5A7P197TW2Zq5YtKLSselVk3huNt7bsPPMUWU/a2Ouvt6hdZ5GW6klb1rmnLNG1ACIF5En1zHP3p9o0nlTK8YuIFDeVfvwdLfpTdez7vslTv86ftBmpu/9rMnOfdl/Y+jx7kTx6M83y863k+rOuTahfRzIbf+DQIGawY9dYrvWUMa5G263MbSzSTD/eM6LpHn83aHWPv2jRb1UtN77h59ty59GbaZaxf81JI1y7cUuhXH9WXr6oRutp5XqDIjn+IvOKTFUV18+001Ry/D2rHUUf9ufGi+TRm2mWn796/SOFc/1l3Z+g0Xpaud6gyHYrcxuLNNOv94yo8g5cQXlsxyhZfzu1cl+AZjn0rGU2el2Z9ycoel1BK+NKm15kXpGp6td7RuS5A9dK4M3ASPzvvwMvqH5oveWw4aFCefQ8y2ska5mNXlfm/QmKXlfQyrjSppe5jUWa6dd7RmQWfnf/QHwXroOBE939ne7+TuAkop78XW/ezNYy9UXVcuNF8ujNNMvPrzl5ceFcf1n3J2i0nlauNyiy3crcxiLN9Os9I/Ic418C7E483g0srWQ0Jbv7A2cWLv4jdZ/kycx91vy1Ez1F8ujNNMvPf3D1isK5/rTxJd9bch3JbPzw0CDzZw/mWk8r1xsU2W5lbmORZvr1nhF5cvwXEV2pez1RH/1XAV9x9/9d/fAiyvGLiBQ3lRz/h8zsn4Hfiif9V3e/o+wBVqVopDOZZZ89Yxo/ffKZzHmXL5rDyUcdtC9TnqVo7/qatBx/o374ybzx8OxB3GHnaL7sfda6y8oul9mPv17ytTXJZfRjDlvap1M/P1WuN1eOP+7GudzdP29mC4ED3P1npYwgh27P8edRNPtbtO98s/mLrL/s7HKZ/fjrNbs2YdWyBdz+8M6ezWFLZ3Uqx1/WelvO8ZvZ+4A/A9bGkwaBL+Zecwd1S9GH4tnfon3nm81fZP1lZ5fL7MdfdJ5bH9jWlzlsaY9O5firXm+ek7uvAl4BPAPg7o8RxTyloCLZ36J956fSFz/vfK1ml8vsx9/KPEXGJJLUqRx/1evNU/h3e3Q8yAHMbE4paw5Qkexv0b7zU+mLn3e+VrPLZfbjb2WeImMSSepUjr/q9eYp/F8xs78Hhs3sPKK7cX22lLVXrF05/jyKZn+L9p1vNn+R9ZedXS6zH3/ReVYtW9CXOWxpj07l+Kteb55Uz0fN7HTgKaLbML7X3W8qZe0Vu/sDZ/Zsqqc2b95UT3L+qaZ66pc11URBs+XVTuC2kuqpf22NUj1ShrJ/F5Lcnad/vYedu8bYvms323eNsWPXbnbEj1cunc+Gh7YzOjbecjIwS54c/1+6+581m1Yl5fhFpJs9OzbOjl1j7BjdzfZnogK+PX68Y9cY25+JHu8cnVjg9+zNrr9zZ01n/uwZfOz1x/GbS1u7m2DLOX7gdKJUT9LLUqZ1lbRsdxXmx3vWO0bHMufJuwdbv2ea7IlfVh/8Rv34m423W/acs+5TkLW9yhh3p997p9cfivG9zlOj0R73V+98jC/e9nN+9cxujOgk55wZAyw/ZC6zZwxEhT4u8I0SdTOnT2P+7BkMzx5k/uwZLF90AMOzZzA/fnxg/HX+7MF90w8cGmT6QHXNkzP3+M3szcD/AJYB9yeemgv8m7ufU9mo6hTd4y+r73zZGuXSi+b287y+fv6i2yU53m7pS55nO9W0et+CPOts53vv9Pp7kbuza/c42+M969rhk1qh3r5r96RDLNt3jfHUs2M021c0YOlBczhq4Zz9BXxOVNiHhxIFfE5U0Ge1eB/uMmTt8Tcq/AcC84EPAxcmnnra3bdVMsoMRQv/srXf6Mo2vQNmPPDhs1KfW3XJzal3+Ko3MjzErRe+JPfrk/MX3S7J8eZZfjvk3U41tb8I6hUZd6ffe6fX32lj43sn7F3XCnhUzGvTJx5C2bFrjN3jezOXecDM6VGhjve2hxN73MNDg3zy5p+yfVf2X/G9su0LH+px953ATjP7BLDN3Z+OFzTXzE529/XVDXdqurHoQ+NxVZWxT04vul2S83dLX/Ki62vlvgV5523Xe+/0+svi7jz17J6me93JE5w7do3x77/ek7nMwQGbULSPPHhOxuGTGfsK/fDQDGZMb3wY5S++/uOGz/fatq+X5xj/p4ETE4+fSZnWVbL28jqtUeb8sLp7/Taar8jrk/MX3S7J8eZZfjvk3U41We+56DUVnXzvnV5/mmfHosMo259JnMDctf9E5o7R+j30MXaOjjGecTLTDObNGtxXqA86YAbPXXTAvj3y+bMHOTBxXLw2ffaMAayCezE0+znr9etA8hR+88TxIHffa2Z5Xtcxa05e3JXH+Btlzi844+hcx/gb9cFPOw6cnL/odkmON8/y2yHPdqppdIy/6DUVnXzvVa5/fK9He9i1Qv3M/kK9I5FAqU3fGZ/4fHYs+zDK0ODAhEL9/OfMSxxSGZywh177euDQIAPTuudmOo1+zvrhOpA8BfxBM3sb0V4+RCd8H6xuSFOXle2uQlmpnrS8cJFUT568cVpePm+qp8o8cxFZ1zc0SvWsPGLBlMbd6feeZ/3uzjO7x6O97X2HT+JC/czEE5v7i/xunno2+zDKwDRjeGj/cfDD589mxchgongnjosnCnsnT2aWpdHPWT8kqvLk+BcBfwO8hCjR9G3g7e7+ZJPXfQ54OfCkux8TT1sAfJnoRi4PAa939+3NBqkcv4Rk9569kw6TZB3/rh0f3zm6m7HxBpnwmdMZjlMmBw5Njg/On5OcPoPhOYPMnTm9ksMo0j5T6cf/JHB2C+u8AvgU8A+JaRcC33b3S8zswvhxJdcDtCvHP82inO7o2N7U48nLF83hpnecljqu5B53nqttG2Xw8+6RZF0rkFxGTdG++O1W/16WHjTEbQ9ub6mnf9F15dnr27vXeerZsYZJlGTU8LEdo+zYNUajn9gZ06dFBXso2rtetvAA5s/Zn0bZd/x7Ti0PHj0erDATHoqs60eq+gugI/34zezd7v4RM/skTP5ZdPe3NV242VLg64k9/s3Aae7+uJkdCtzi7k0PlvV6jr9W/IuOK0/P+mavSyqSgU/qxlsb5n0vZYz9+tsfZe11m3h2z/7j2oMDxiuPH+GIBbP374mPTtwT3zmanQmfZuzbwz5w9iC/HtvL5l88PeGDd3DAOO+3juKsFYfuK+RDg9WczJTGGv28VXFNRdX9+Bvt8d8bfy3zGMsh7v44QFz8F5W47H3y9HFvp1q/n6LjqvXfXn3CSKHXJl+XlKfHf5qr1z/SdYU/73upH3t9JnxH3SGTtEMpTz7960nLHRt3rtn4KBBdzVm7YGd4aAYjw0OZSZTaoZV5swaZljiZueqSmyf9tTg27nz1zsd495nPa3UzSUka/bxl/b6Vvb4y19Mox/+1+OuVU15LC8zsfOB8gCVLlhR6bTdGOaG1cTXrWd/sdc2m5dGN2zNvpHPcnd//5PeiyOEzYzydNxM+NIMjDprN8YuH+fKG7A/dzR88k5nTp34ys1+y+v2q2f9D2f9PVf88ZBZ+M/saKYd4atz9FS2s7wkzOzRxqCfzBLG7XwZcBtGhniIr6eYcf9FxJXvWF3ltWs64aAa+ptWe93nVGlxtTznuvX/PfP9x8Z0NElRpapnwfScv5wxOKPC1Y+JzMjLh37v/l5lXzpZR9KE7s/qyX7tz/VX/PDQ61PPR+Ourgeew/3aLa4gSOa24AXgDcEn89astLqehbsvxL18U3bum6Ljqe9YXOcafljMukoFPytMXH6JM+M7RiYdR6i+pn3ylZuNM+KzBWoOr6OTl0c+Zy/DsGTz51LPcsnlrw+6GUM4x/nbk+Dt9rYA01u5cf9U/D40O9fwrgJn9hbv/duKpr5nZd5st2MyuBk4DDjazR4H3ERX8r5jZG4GHgddNYeyZ2pnjL5LqaZSjb5bqaZbBz5MyaHStQFqqZxpwxorncMZvPIcb7nps3/jqHQcAABSRSURBVIU8ySs1o2LevMFVMhM+PHsGI8Oz+I3D5qXmwPdFCptkwtuV6mlHjr/T1wpIY+3O9Vf985Anx38v8Hvu/mD8+EjgG+7+/FJGkINy/K2rZcJ3jE7uCb59V3Tcu/5KzZ1NGlzNnTl9Xy+UtCsy03qlzJ05fcLJTBGp3lT68f8pcIuZ1a7WXQq8qcSxVeLkD93EE0/vrnw9tU/8967bNOlOX8m9zrTrCvLuLay7Ywsf+eZ9PLbzWQ6ZO5MZ041Htj+bOf+COfHVxM0y4QPTmDU4jV27x9mz15k1OI3jFw9z/OL5mQU8TyZ83R1buPj6e9q+51pl7ln98KWmH34Wmu7xA5jZTKCWKbvP3Sfn2ypUdI+/XUU/r+WL5mTewnHGwDT+88lLeO6iA1JPZD6yfZStKXHCZmo3jqgZHDD+24uO4veOjTLhw0ODfOtHv+A9199Tap/3TvWOr3K96ocvNb32s5C1x9/0cj4zmw1cALzV3e8ClpjZyysYY2m6qegDDe/bu3t8L1f820NcvO4ePvqtn3D1Dx7mtgd/xeM7n2VoxgD/3qCXSiP1H+dj484Ndz3GMSMHMjI8xJyZ0/not36SmRVuVaP8cZWqXG+n3pN0n375WchzqOfzwEbg1Pjxo8A/Al+valAhWv+elzI8e3BSPPDIC/+ptHXUZ4CryAp3Ko9e5XqVsZeafvlZyNPAY5m7fwQYA3D3UaIjCVKSkeEhDpk3KzUTXmY+uH5ZjXr7l7WOMpbZ6fV26j1J9+mXn4U8hX+3mQ0RHz0ws2VAW4/xF3XI3BmdHsIEtRx/mmbZ3AvOOJqhFtrc1vc2T1tP2rKnmhWuYpmdXm+n3pN0n375WchT+N8HfBNYbGZXEbVlfnelo5qi9Red3rbiPzI8xF//wfHMmzm5OA+Yce4pS7jpHadx7ilLJl0BOzI81PSk0OoTRvjwq1cwMjyExa9p9EFSW+fHXnfchNekrSdt2VM9SVXFMju93k69J+k+/fKz0DDVY9H164cDu4BTiA7x3Obuv2zP8CLK8YuIFNdSjt/d3czWuftJQHlnGdugin7882YOTMrqT0V9jj/Z7ztNfUQzqf4q4AOHBjGLsvx5ssaNsslp27Lbe/WXrR3Z7X7Ih0tvyJPquc3MftPdf1j5aEpSVT/+Mos+RB0m1163ad/jZn10Gn2Ejbtz6wPb9j1O3goyuZ60QlKfTU7Ov+Hn21K35bj7vun9XvwbbZ8yLxCreh0iNXmO8b+YqPg/YGZ3m9kmM7u76oFNRbf142+klgFutVd+0fWkaZRNbrYte2lbt6od2e1+yYdLb8izx/+yykdRsm5sydxIuzLARTPIj+0YbfhXBvTetm5FO7Lb/ZIPl96QucdvZrPM7O1EV+2eCWxx95/X/rVthC2oun982Q4bHmpLDrhoBvmw4aGm27LXtnUr2pHd7pd8uPSGRod6rgRWApuI9vo/1pYRlSBv//huUMsAt5rXL7qeNI2yyc22ZS9t61a1I7vdL/lw6Q2NDvW8wN1XAJjZ5cAP2jOkqauqH3/VqR6gI6meRr2/a8+FnOpRP37pN5k5fjO73d1PzHrcTsrxi4gU10qO/zgze6r2emAofmxEEf95FYyzdM+76Bs8O97eE5AjdXeDylK/11yf4067O1bWvXezevuf85nvT4h5Ll80h12792beRUhZ8u6k/5f26+dtnqsff6e1usffiaLfinNPWcLKIxa0dD/cpPq+4PVFv9lrX3PSCNdu3NIzvcZD0Ws94PtBv2zzlvvx97JeKPoQHT8vI8dfn/vOW/Rrr716/SPKknchZfzbr9+3eV8X/l4x7l5aXnsqy8k6LKUseWcp499+/b7NVfi7wIBZaXntqSwnK5OvLHlnKePffv2+zfu68M8a6I2Li9acvLiUHH997nvVsgWFXrvm5MXKknchZfzbr9+3eV8X/vs+dFZHiv/I8BCrli3IddXruacs4YOrV6T2+T73lCWMxHsYtWVlLTOtL/hV5506qfgvXzRn0jJrr/3g6hV90Wu83/RLD/he0u/bvG9TPad//JaGNzkvw/JFc7jpHacBE1sqp8Uks6RFxiD9Qp60dWR9zbPuNMkWzCFdpCXSj7JSPX1Z+NtR9GuWL5rDW168PDOK2SgClhYZGxwwcBjb6xOWkRa1bKZo/CyrnXXtrxIR6S1BxTnbVfRr62oUxSzaDnls3CcU/doy0qKWzRSNn2W1WA6h9bJISPqy8Ldbs4hXGdGwVnsOlbGOEFovi4REhb8EzSJeZUTDWm1/XMY6Qmi9LBKSviz8yxfNaeu6GkUxi7ZDHhwwBqdNLLRZUctmisbPslosh9B6WSQkee7A1XNuesdpbU/1AIVTPVmteNOmrT5hhJVHLKg01VPfzlqpHpH+1JepHhERaa0tc5WDeQh4GhgH9qQNbKpO/tBNPPH07tzzjwwP8aunny3U2G3ezAHu/sCZQPMWrq20eC3Spnkk8XyjdSRz+jVTzf6LSG/pyB5/XPhXuvsv88xfdI+/aNGfinkzB/hfq1c0bOHaSovXtNcUVb+OrJx+o9eISO8KKsffrqIP8NSvx5u2cG2lxWsVbZrz5PH7qfWsiKTrVOF34FtmttHMzk+bwczON7MNZrZh69atbR5eMc1y+q3k+Kto05w3j98vrWdFJF2nCv+q+P69LwPeYma/XT+Du1/m7ivdfeXChQvbP8ICmuX0W8nxV9GmOW8ev19az4pIuo4Ufnd/LP76JHA98MIyl3/I3BllLq6heTMHmrZwbaXFaxVtmvPk8fup9ayIpGt74TezOWY2t/Y98LvAPWWuY/1Fpxcu/iPDQ4VbONdSPc1auLbS4rVom+bk81nr+ODqFZx7ypJJe/717Zl1Ylekv7U91WNmRxHt5UMUJ/2/7v6hRq9Rjl9EpLiuyfG7+4PAcVWvp+iVuyPDQ2zJOKm5atkCrjrv1Mp71Wfl9rNy+XnGk+daAOX3RbK1eq+NbtaXV+5W0a7hkLkzUmOiZfWqz5PbT2bs8/TOL3ItgPL7IpM1+h3qhd+ZoHL8VfToybo2oKxe9Xly+8mMfZ7e+UWuBVB+X2SyVu+10e36svC3U1m96vNm52vz5emdXzSPr/y+yESt3muj26nwT1FZverzZucPq0v1NBpP0Ty+8vsiE7V6r41u15eFv4p+/Fnx0LJ61efJ7Scz9nl65xe5FkD5fZHJWr3XRrfry8J/0ztOK1z8Rxp8cq9atoD1F50+IQM/YFbqTcgb5fbTcvn1mfy08eS9FkD5fZF0yd8h6J/fmb5M9YiISBfl+NulUSa+lY+6rDtcbfj5tkn97avK+LbS078bli0i3aUv9/jL6GWfx8A0Y3xv+vYrO+PbSk//bli2iHROUDn+MnrZ55FV9KH8jG8rPf27Ydki0n36svB3S7a2zHG00tO/G5YtIt2nLwt/t2RryxxHKz39u2HZItJ9+rLwl9HLPo+BadkXb5Wd8W2lp383LFtEuk9fFv5mmfhWpPW//9jrjkvtb19FxreVnv7dsGwR6T59meoREZEAc/z1kr3r680aMO770Fn7Hmf13666l307svTNeosrzy/S/4LY48/qXZ9UK/6tXANQRua9HVn6Zr3FX3PSCNdu3KI8v0ifCCrHXy9Pz/xnx6MPwFauASgj896OLH2z3uJXr39EeX6RAARR+Iv0zG81uz7VzHs7svTNlpW1nZTnF+kvQRT+Ij3zW82uTzXz3o4sfbNlZW0n5flF+ksQhT9Pz/xZA1HRa+UagDIy7+3I0jfrLb7m5MXK84sEIIhUT61HfZ5UT+0kZrtTPcn1VpWoafTeautaecQCpXpE+lwQqR4RkRAFm+NPy6Wn9dBvtmef9bWq3vsiIlXp6z3+tNx6ox76rVLWXUS6UZA5/rTcetlFH5R1F5He0teFv535c2XdRaRX9HXhb2f+XFl3EekVfV3403LrjXrot0pZdxHpJX1d+NP6zGf10E/22a/17k9Oz/qq3vUi0ms6kuoxszOBTwADwGfd/ZJG8yvHLyJSXNfk+M1sAPhb4HTgUeCHZnaDu/+4XWPI6s2/atkCrjrv1HYNo3TqpS8ieXTiUM8Lgfvd/UF33w18CXhlu1Ze682f1rrh1ge2cc5nvt+uoZSqds3Clh2jOLBlxyhrr9vEuju2dHpoItJlOlH4R4Bkg/xH42lt0aw3/60PbGvTSMrVjn7+ItIfOlH402I1k3a/zex8M9tgZhu2bt1a2sqL9ObvJe3o5y8i/aEThf9RINkn+XDgsfqZ3P0yd1/p7isXLlxY2sqL9ObvJe3o5y8i/aEThf+HwHIzO9LMZgBnAze0a+XNevOvWragTSMpVzv6+YtIf2h7qsfd95jZW4EbieKcn3P3H7Vr/Y168/dyqqcd/fxFpD/0dXdOEZGQBdmdU0REJlPhFxEJjAq/iEhgVPhFRAKjwi8iEpieSPWY2Vbg5wVfdjDwywqGU7ZeGSf0zlg1znL1yjihd8barnEe4e6TroDticLfCjPbkBZj6ja9Mk7onbFqnOXqlXFC74y10+PUoR4RkcCo8IuIBKafC/9lnR5ATr0yTuidsWqc5eqVcULvjLWj4+zbY/wiIpKun/f4RUQkRV8WfjM708w2m9n9ZnZhp8dTY2aLzew7Znavmf3IzP4knr7AzG4ys5/GX+d3eqwQ3R/ZzO4ws6/Hj480s/XxOL8ct9Xu9BiHzewaM7sv3q6ndvH2/NP4//0eM7vazGZ1wzY1s8+Z2ZNmdk9iWuo2tMjfxL9bd5vZiR0e56Xx//3dZna9mQ0nnlsbj3OzmZ3RrnFmjTXx3LvMzM3s4Phx27dp3xX+xM3cXwa8AFhjZi/o7Kj22QO8092fD5wCvCUe24XAt919OfDt+HE3+BPg3sTjvwT+Kh7nduCNHRnVRJ8AvunuzwOOIxpv121PMxsB3gasdPdjiFqSn013bNMrgDPrpmVtw5cBy+N/5wOfbtMYIX2cNwHHuPuxwE+AtQDx79XZwG/Er/m7uDa0yxVMHitmthg4HXg4Mbn929Td++ofcCpwY+LxWmBtp8eVMdavxj8Em4FD42mHApu7YGyHE/3CvwT4OtEtM38JTE/bzh0a4zzgZ8TnqhLTu3F71u41vYDoPhhfB87olm0KLAXuabYNgb8H1qTN14lx1j33KuCq+PsJv/dE9/84tZPbNJ52DdEOykPAwZ3apn23x0+Hb+ael5ktBU4A1gOHuPvjAPHXRZ0b2T5/Dbwb2Bs/PgjY4e574sfdsF2PArYCn48PSX3WzObQhdvT3bcAHyXa03sc2AlspPu2aU3WNuzm368/Bv45/r7rxmlmrwC2uPtddU+1faz9WPhz3cy9k8zsAOBa4O3u/lSnx1PPzF4OPOnuG5OTU2bt9HadDpwIfNrdTwCeoQsO66SJj5G/EjgSOAyYQ/Qnfr1Ob9NmuvHnADO7iOhQ6lW1SSmzdWycZjYbuAh4b9rTKdMqHWs/Fv5cN3PvFDMbJCr6V7n7dfHkJ8zs0Pj5Q4EnOzW+2CrgFWb2EPAlosM9fw0Mm1ntdp3dsF0fBR519/Xx42uIPgi6bXsC/CfgZ+6+1d3HgOuA/0j3bdOarG3Ydb9fZvYG4OXAOR4fK6H7xrmM6EP/rvj36nDgdjN7Dh0Yaz8W/o7ezL0RMzPgcuBed/944qkbgDfE37+B6Nh/x7j7Wnc/3N2XEm2/m939HOA7wGvj2bphnL8AHjGz2h3lXwr8mC7bnrGHgVPMbHb8c1Aba1dt04SsbXgD8IdxEuUUYGftkFAnmNmZwJ8Br3D3XYmnbgDONrOZZnYk0YnTH3RijADuvsndF7n70vj36lHgxPhnuP3btJ0nO9p4UuUsojP8DwAXdXo8iXG9iOhPuLuBO+N/ZxEdP/828NP464JOjzUx5tOAr8ffH0X0y3M/8I/AzC4Y3/HAhnibrgPmd+v2BD4A3AfcA3wBmNkN2xS4mui8wxhRQXpj1jYkOizxt/Hv1iailFInx3k/0fHx2u/T/0nMf1E8zs3Ayzq9Teuef4j9J3fbvk115a6ISGD68VCPiIg0oMIvIhIYFX4RkcCo8IuIBEaFX0QkMCr80vPM7FVxt8Pn5Zj3j8zssCms67Rat9KpKGs5Iq1Q4Zd+sAb4HtHFZs38EVHLBJFgqfBLT4v7Hq0iupjn7Lrn3m1mm8zsLjO7xMxeC6wErjKzO81syMweSvRFX2lmt8Tfv9DM/i1u/vZviauDs8ax3sx+I/H4FjM7Kc9yzOz9ZvauxON74iZ+mNm5ZvaDeLx/b9E9EgbM7Ip4vk1m9qetbT0J1fTms4h0tdVE/fh/YmbbzOxEd7/dzF4WP3eyu+8yswXuvs3M3gq8y903AETdE1LdB/y2u+8xs/8E/G/gNQ3G8SXg9cD74t42h7n7RjObV3A5+5jZ84E/AFa5+5iZ/R1wDvAjYMSjvv5Y4uYjInmo8EuvW0PUQA6i4rsGuJ2oKdrnPe7f4u7bCi73QOBKM1tO1GZjsMn8XyG6Kcj7iD4A/rHF5SS9FDgJ+GH8ATVE1Czta8BRZvZJ4J+AbxVYpogKv/QuMzuIqHPoMWbmRHe1cjN7N1H/kzz9SPaw/5DnrMT0vwC+4+6vig+73NJoIe6+xcx+ZWbHEu2lv6nAcpJjSI7DgCvdfW39C8zsOKIbubyF6IPmjxuNTyRJx/ill70W+Ad3P8KjroeLie7I9SKiveA/jvugY2YL4tc8DcxNLOMhor1qmHgI5kBgS/z9H+Ucz5eIbl5zoLtvKrCch4jaSWPR/VaPjKd/G3itmS2qvQczOyI+JzHN3a8F/rz2WpG8VPill60Brq+bdi3wn939m0TtbjeY2Z1A7eTpFcD/qZ3cJeqY+Qkz+3/AeGI5HwE+bGa3Ev0lkcc1RCeYv1JwOdcCC+Jxvpmosyzu/mPgYuBbZnY30aGkQ4nuznRLPP8VxPeZFclL3TlFRAKjPX4RkcCo8IuIBEaFX0QkMCr8IiKBUeEXEQmMCr+ISGBU+EVEAqPCLyISmP8PQjm8PEj7RXIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_val=np.squeeze(test_val.astype(np.int64))\n",
    "\n",
    "plt.scatter(test_val,y_pred)\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "\n",
    "plt.plot(np.unique(test_val), np.poly1d(np.polyfit(test_val, y_pred, 1))(np.unique(test_val)))\n",
    "\n",
    "plt.text(70, 50, 'R-squared = %0.2f' % R2SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 4, ..., 3, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(test_val.astype(np.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 4, ..., 7, 7, 7], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
