{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from PIL import Image\n",
    "from imutils import paths\n",
    "from os import path\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "import pandas as pd\n",
    "keras.__version__\n",
    "IMAGE_DIMS = (350,250,3)\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_arr = np.load('./new_date_arr.npy',allow_pickle=True)\n",
    "dust_arr = np.load('./result_arr_avg_7.npy',allow_pickle=True)\n",
    "wind_arr = np.load('./wind_arr.npy',allow_pickle=True)\n",
    "humi_arr = np.load('./humi_arr.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 18126 images (22940.04MB)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time() \n",
    "imagePaths = sorted(list(paths.list_images('./dataset/image')))\n",
    "image_arr = []\n",
    "\n",
    "for i in imagePaths:\n",
    "    img_name = int(path.splitext(path.basename(i))[0])\n",
    "    \n",
    "    if img_name in date_arr :\n",
    "        image = Image.open(i)\n",
    "        image = image.resize((IMAGE_DIMS[0],IMAGE_DIMS[1]))\n",
    "        image = img_to_array(image)\n",
    "        image_arr.append(image)\n",
    "        \n",
    "image_arr = np.array(image_arr, dtype=\"float\") / 255.0        \n",
    "print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(len(imagePaths), image_arr.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11186,)\n",
      "(11186, 250, 350, 3)\n",
      "(8948, 250, 350, 3)\n",
      "(2238, 250, 350, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "con_data_img = image_arr\n",
    "con_data_val = dust_arr\n",
    "\n",
    "print(wind_arr.shape)\n",
    "con_data_wea = np.concatenate([wind_arr.reshape(len(wind_arr),1),humi_arr.reshape(len(humi_arr),1)], axis=1)\n",
    "\n",
    "\n",
    "# 국내는 PM2.5이 16이상이면 보통\n",
    "# for i in range(0,dustvalue.shape[0]):\n",
    "#     if int(dustvalue[i]) > 0 :\n",
    "#         con_data_img.append(data[i])\n",
    "#         con_data_val.append(dustvalue[i])\n",
    "#         con_data_wea.append(add_info[i])\n",
    "        \n",
    "# con_data_img, con_data_val, con_data_wea = shuffle(np.array(con_data_img), np.array(con_data_val), np.array(con_data_wea), random_state=0)\n",
    "# con_data_img = np.array(con_data_img)\n",
    "# con_data_val = np.array(con_data_val)\n",
    "# con_data_wea = np.array(con_data_wea)\n",
    "\n",
    "num = int(con_data_img.shape[0]*0.8)\n",
    "\n",
    "train_img = con_data_img[:num]\n",
    "train_val = con_data_val[:num]\n",
    "train_wea = con_data_wea[:num]\n",
    "\n",
    "test_img = con_data_img[num:]\n",
    "test_val = con_data_val[num:]\n",
    "test_wea = con_data_wea[num:]\n",
    "\n",
    "print(con_data_img.shape)\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, LSTM, GRU, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "chanDim=-1\n",
    "model = Sequential()\n",
    "\n",
    "# CONV => RELU => POOL\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(IMAGE_DIMS[1], IMAGE_DIMS[0],3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "image_input = Input(shape=(IMAGE_DIMS[1], IMAGE_DIMS[0],3))\n",
    "encoded_image = model(image_input)\n",
    "\n",
    "# 다음은 문제를 벡터로 인코딩할 숫자 모델을 정의합니다\n",
    "numeric_input = Input(shape=(2,))\n",
    "embedded_numeric = Embedding(input_dim=100, output_dim=256, input_length=2)(numeric_input)\n",
    "\n",
    "# numeric_input2 = Dense(256, activation=\"linear\")(embedded_numeric)\n",
    "# print(embedded_numeric.shape)\n",
    "\n",
    "#numeric_input2 = GRU(256)(embedded_numeric)\n",
    "numeric_input2 = GRU(256)(embedded_numeric)\n",
    "# print(numeric_input2.shape)\n",
    "\n",
    "\n",
    "# numeric_input = Input(shape=(8,), dtype='float32')\n",
    "# numeric_input1 = Dense(1000,activation='linear')(numeric_input)\n",
    "# numeric_input2 = Dense(100,activation='linear')(numeric_input1)\n",
    "\n",
    "# 질문 벡터와 이미지 벡터를 연결해 봅시다:\n",
    "merged = keras.layers.concatenate([encoded_image, numeric_input2],axis=-1)\n",
    "\n",
    "output = Dense(1)(merged)\n",
    "\n",
    "# 그리고 상층의 로지스틱 회귀를 수치에 대해 학습시킵니다:\n",
    "# output = Dense(1024, activation='softmax')(merged)\n",
    "# output = Dense(128, activation='softmax')(output)\n",
    "# output = Dense(1)(output)\n",
    "# 다음은 최종 모델입니다:\n",
    "model = Model(inputs=[image_input, numeric_input], outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\teado\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "8948/8948 [==============================] - 37s 4ms/step - loss: 223.5238 - acc: 0.0058\n",
      "Epoch 2/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 165.2596 - acc: 0.0079\n",
      "Epoch 3/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 129.3332 - acc: 0.0117\n",
      "Epoch 4/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 108.0393 - acc: 0.0133\n",
      "Epoch 5/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 92.9314 - acc: 0.0137\n",
      "Epoch 6/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 88.2299 - acc: 0.0129\n",
      "Epoch 7/200\n",
      "8948/8948 [==============================] - 38s 4ms/step - loss: 77.4003 - acc: 0.0145\n",
      "Epoch 8/200\n",
      "8948/8948 [==============================] - 35s 4ms/step - loss: 70.2222 - acc: 0.0135\n",
      "Epoch 9/200\n",
      "8948/8948 [==============================] - 35s 4ms/step - loss: 62.8557 - acc: 0.0144\n",
      "Epoch 10/200\n",
      "8948/8948 [==============================] - 35s 4ms/step - loss: 58.2525 - acc: 0.0153\n",
      "Epoch 11/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 48.6255 - acc: 0.0171\n",
      "Epoch 12/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 50.6805 - acc: 0.0170\n",
      "Epoch 13/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 43.1682 - acc: 0.0172\n",
      "Epoch 14/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 33.9000 - acc: 0.0178\n",
      "Epoch 15/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 35.3602 - acc: 0.0170\n",
      "Epoch 16/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 31.7729 - acc: 0.0187\n",
      "Epoch 17/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 30.3500 - acc: 0.0215\n",
      "Epoch 18/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 27.2516 - acc: 0.0187\n",
      "Epoch 19/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 33.3480 - acc: 0.0190\n",
      "Epoch 20/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 27.0099 - acc: 0.0196\n",
      "Epoch 21/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 26.2593 - acc: 0.0206\n",
      "Epoch 22/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 22.8459 - acc: 0.0187\n",
      "Epoch 23/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 23.0917 - acc: 0.0201\n",
      "Epoch 24/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 19.4352 - acc: 0.0219\n",
      "Epoch 25/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 19.4620 - acc: 0.0224\n",
      "Epoch 26/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 19.2471 - acc: 0.0191\n",
      "Epoch 27/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 17.0378 - acc: 0.0218\n",
      "Epoch 28/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 17.1323 - acc: 0.0237\n",
      "Epoch 29/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 16.5113 - acc: 0.0259\n",
      "Epoch 30/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 15.0753 - acc: 0.0247\n",
      "Epoch 31/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 15.6996 - acc: 0.0256\n",
      "Epoch 32/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 16.0417 - acc: 0.0259\n",
      "Epoch 33/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 15.0309 - acc: 0.0234\n",
      "Epoch 34/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 13.2019 - acc: 0.0236\n",
      "Epoch 35/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 12.9110 - acc: 0.0282\n",
      "Epoch 36/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 13.1956 - acc: 0.0279\n",
      "Epoch 37/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 15.3747 - acc: 0.0255\n",
      "Epoch 38/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 11.9624 - acc: 0.0269\n",
      "Epoch 39/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 13.3842 - acc: 0.0244\n",
      "Epoch 40/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 11.3582 - acc: 0.0262\n",
      "Epoch 41/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 12.4024 - acc: 0.0234\n",
      "Epoch 42/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 13.2804 - acc: 0.0263\n",
      "Epoch 43/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 10.6788 - acc: 0.0270\n",
      "Epoch 44/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 10.1522 - acc: 0.0329\n",
      "Epoch 45/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 11.8583 - acc: 0.0277\n",
      "Epoch 46/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 9.9503 - acc: 0.0247\n",
      "Epoch 47/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 9.0271 - acc: 0.0306\n",
      "Epoch 48/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 11.1180 - acc: 0.0323\n",
      "Epoch 49/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 10.5118 - acc: 0.0279\n",
      "Epoch 50/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.9182 - acc: 0.0304\n",
      "Epoch 51/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.1630 - acc: 0.0307\n",
      "Epoch 52/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 8.9364 - acc: 0.0278\n",
      "Epoch 53/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 9.4253 - acc: 0.0285\n",
      "Epoch 54/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.4991 - acc: 0.0320\n",
      "Epoch 55/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.8295 - acc: 0.0332\n",
      "Epoch 56/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 8.1764 - acc: 0.0321\n",
      "Epoch 57/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.6443 - acc: 0.0326\n",
      "Epoch 58/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.6985 - acc: 0.0329\n",
      "Epoch 59/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.1547 - acc: 0.0348\n",
      "Epoch 60/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 9.1373 - acc: 0.0335\n",
      "Epoch 61/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.6507 - acc: 0.0348\n",
      "Epoch 62/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.7295 - acc: 0.0313\n",
      "Epoch 63/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.7577 - acc: 0.0325\n",
      "Epoch 64/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.1945 - acc: 0.0361\n",
      "Epoch 65/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.6038 - acc: 0.0352\n",
      "Epoch 66/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.7493 - acc: 0.0320\n",
      "Epoch 67/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.0589 - acc: 0.0372\n",
      "Epoch 68/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.0695 - acc: 0.0349\n",
      "Epoch 69/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.4267 - acc: 0.0367\n",
      "Epoch 70/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.2561 - acc: 0.0349\n",
      "Epoch 71/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 9.9248 - acc: 0.0334\n",
      "Epoch 72/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.4721 - acc: 0.0321\n",
      "Epoch 73/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 7.6786 - acc: 0.0363\n",
      "Epoch 74/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.3324 - acc: 0.0329\n",
      "Epoch 75/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.5192 - acc: 0.0386\n",
      "Epoch 76/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 6.6332 - acc: 0.0344\n",
      "Epoch 77/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 5.3866 - acc: 0.0401\n",
      "Epoch 78/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 6.2209 - acc: 0.0354\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.2809 - acc: 0.0330\n",
      "Epoch 80/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.9228 - acc: 0.0353\n",
      "Epoch 81/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.0028 - acc: 0.0341\n",
      "Epoch 82/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.2691 - acc: 0.0373\n",
      "Epoch 83/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.0449 - acc: 0.0389\n",
      "Epoch 84/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.0638 - acc: 0.0402\n",
      "Epoch 85/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 8.3939 - acc: 0.0313\n",
      "Epoch 86/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.5331 - acc: 0.0368\n",
      "Epoch 87/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.7248 - acc: 0.0365\n",
      "Epoch 88/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.8442 - acc: 0.0365\n",
      "Epoch 89/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.4392 - acc: 0.0364\n",
      "Epoch 90/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.8337 - acc: 0.0386\n",
      "Epoch 91/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.8871 - acc: 0.0369\n",
      "Epoch 92/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.8930 - acc: 0.0352\n",
      "Epoch 93/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.6984 - acc: 0.0388\n",
      "Epoch 94/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.7932 - acc: 0.0370\n",
      "Epoch 95/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.0629 - acc: 0.0389\n",
      "Epoch 96/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.4207 - acc: 0.0374\n",
      "Epoch 97/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 6.2545 - acc: 0.0353\n",
      "Epoch 98/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.9621 - acc: 0.0369\n",
      "Epoch 99/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.4061 - acc: 0.0390\n",
      "Epoch 100/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 7.0438 - acc: 0.0352\n",
      "Epoch 101/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.8387 - acc: 0.0403\n",
      "Epoch 102/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6715 - acc: 0.0419\n",
      "Epoch 103/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.0186 - acc: 0.0386\n",
      "Epoch 104/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.6491 - acc: 0.0391\n",
      "Epoch 105/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.3985 - acc: 0.0424\n",
      "Epoch 106/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.1962 - acc: 0.0409\n",
      "Epoch 107/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.7515 - acc: 0.0388\n",
      "Epoch 108/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.2323 - acc: 0.0414\n",
      "Epoch 109/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.1565 - acc: 0.0379\n",
      "Epoch 110/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.2380 - acc: 0.0432\n",
      "Epoch 111/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 5.1984 - acc: 0.0408\n",
      "Epoch 112/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 4.8521 - acc: 0.0396\n",
      "Epoch 113/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.7126 - acc: 0.0431\n",
      "Epoch 114/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.1408 - acc: 0.0372\n",
      "Epoch 115/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.7471 - acc: 0.0418\n",
      "Epoch 116/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.6935 - acc: 0.0410\n",
      "Epoch 117/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.4682 - acc: 0.0421\n",
      "Epoch 118/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.7496 - acc: 0.0424\n",
      "Epoch 119/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.7558 - acc: 0.0399\n",
      "Epoch 120/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.2659 - acc: 0.0411\n",
      "Epoch 121/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 5.5666 - acc: 0.0435\n",
      "Epoch 122/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.2309 - acc: 0.0422\n",
      "Epoch 123/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.3952 - acc: 0.0439\n",
      "Epoch 124/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.1702 - acc: 0.0357\n",
      "Epoch 125/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.2527 - acc: 0.0430\n",
      "Epoch 126/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9179 - acc: 0.0454\n",
      "Epoch 127/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.5575 - acc: 0.0431\n",
      "Epoch 128/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9327 - acc: 0.0458\n",
      "Epoch 129/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.3999 - acc: 0.0438\n",
      "Epoch 130/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9503 - acc: 0.0473\n",
      "Epoch 131/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.2125 - acc: 0.0446\n",
      "Epoch 132/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.4474 - acc: 0.0402\n",
      "Epoch 133/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.7354 - acc: 0.0428\n",
      "Epoch 134/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9480 - acc: 0.0472\n",
      "Epoch 135/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.1260 - acc: 0.0434\n",
      "Epoch 136/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.7877 - acc: 0.0426\n",
      "Epoch 137/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.1261 - acc: 0.0437\n",
      "Epoch 138/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9501 - acc: 0.0417\n",
      "Epoch 139/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.2768 - acc: 0.0444\n",
      "Epoch 140/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9485 - acc: 0.0445\n",
      "Epoch 141/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.8152 - acc: 0.0464\n",
      "Epoch 142/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.0160 - acc: 0.0455\n",
      "Epoch 143/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9802 - acc: 0.0496\n",
      "Epoch 144/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.8391 - acc: 0.0478\n",
      "Epoch 145/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.0455 - acc: 0.0462\n",
      "Epoch 146/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6974 - acc: 0.0440\n",
      "Epoch 147/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.4171 - acc: 0.0434\n",
      "Epoch 148/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.5634 - acc: 0.0455\n",
      "Epoch 149/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.3651 - acc: 0.0498\n",
      "Epoch 150/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.8774 - acc: 0.0491\n",
      "Epoch 151/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.5074 - acc: 0.0441\n",
      "Epoch 152/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.3228 - acc: 0.0446\n",
      "Epoch 153/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.5681 - acc: 0.0491\n",
      "Epoch 154/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.7426 - acc: 0.0479\n",
      "Epoch 155/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.5661 - acc: 0.0468\n",
      "Epoch 156/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.8747 - acc: 0.0466\n",
      "Epoch 157/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6332 - acc: 0.0464\n",
      "Epoch 158/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.0340 - acc: 0.0497\n",
      "Epoch 159/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.5695 - acc: 0.0484\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9263 - acc: 0.0448\n",
      "Epoch 161/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.3602 - acc: 0.0456\n",
      "Epoch 162/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.9061 - acc: 0.0474\n",
      "Epoch 163/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4045 - acc: 0.0493\n",
      "Epoch 164/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.5480 - acc: 0.0468\n",
      "Epoch 165/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 4.6199 - acc: 0.0430\n",
      "Epoch 166/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 5.4023 - acc: 0.0436\n",
      "Epoch 167/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.7989 - acc: 0.0504\n",
      "Epoch 168/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.7412 - acc: 0.0500\n",
      "Epoch 169/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4334 - acc: 0.0478\n",
      "Epoch 170/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 3.3238 - acc: 0.0475\n",
      "Epoch 171/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 3.9852 - acc: 0.0456\n",
      "Epoch 172/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.0975 - acc: 0.0498\n",
      "Epoch 173/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4016 - acc: 0.0497\n",
      "Epoch 174/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6323 - acc: 0.0489\n",
      "Epoch 175/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 3.1748 - acc: 0.0472\n",
      "Epoch 176/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4464 - acc: 0.0492\n",
      "Epoch 177/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.0531 - acc: 0.0477\n",
      "Epoch 178/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4432 - acc: 0.0497\n",
      "Epoch 179/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.8849 - acc: 0.0429\n",
      "Epoch 180/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6544 - acc: 0.0515\n",
      "Epoch 181/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.3981 - acc: 0.0491\n",
      "Epoch 182/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6420 - acc: 0.0488\n",
      "Epoch 183/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.5763 - acc: 0.0504\n",
      "Epoch 184/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.6462 - acc: 0.0476\n",
      "Epoch 185/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.1959 - acc: 0.0476\n",
      "Epoch 186/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.8906 - acc: 0.0496\n",
      "Epoch 187/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.8115 - acc: 0.0500\n",
      "Epoch 188/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.4281 - acc: 0.0472\n",
      "Epoch 189/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.6760 - acc: 0.0523\n",
      "Epoch 190/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.9529 - acc: 0.0511\n",
      "Epoch 191/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.5648 - acc: 0.0533\n",
      "Epoch 192/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.8954 - acc: 0.0513\n",
      "Epoch 193/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.8671 - acc: 0.0505\n",
      "Epoch 194/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 3.1017 - acc: 0.0465\n",
      "Epoch 195/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 2.6692 - acc: 0.0506\n",
      "Epoch 196/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 2.6358 - acc: 0.0540\n",
      "Epoch 197/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 2.3261 - acc: 0.0521\n",
      "Epoch 198/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 2.7198 - acc: 0.0540\n",
      "Epoch 199/200\n",
      "8948/8948 [==============================] - 34s 4ms/step - loss: 2.8258 - acc: 0.0524\n",
      "Epoch 200/200\n",
      "8948/8948 [==============================] - 33s 4ms/step - loss: 2.9646 - acc: 0.0473\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "#opt = RMSprop(lr=0.005, rho=0.9, epsilon=None, decay=0.0)\n",
    "opt = Adam(lr=0.002, epsilon=None, decay=0.0)\n",
    "model.compile(loss=\"mse\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "# logcosh, mes, \n",
    "H = model.fit([train_img,train_wea], train_val ,batch_size=10, epochs=200)\n",
    "\n",
    "\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save('new-LSTM-adam.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11186, 250, 350, 3)\n",
      "(11186,)\n",
      "(11186,)\n",
      "(11186,)\n",
      "(2238, 250, 350, 3)\n",
      "(2238, 2)\n",
      "[[49.50358  ]\n",
      " [49.55198  ]\n",
      " [49.235924 ]\n",
      " ...\n",
      " [ 8.175073 ]\n",
      " [ 7.1092234]\n",
      " [ 6.650285 ]]\n",
      "(2238,)\n",
      "(2238,)\n",
      "[52 55 55 ...  3  4  4]\n",
      "[49 49 49 ...  8  7  6]\n"
     ]
    }
   ],
   "source": [
    "print(image_arr.shape)\n",
    "print(dust_arr.shape)\n",
    "\n",
    "print(wind_arr.shape)\n",
    "print(humi_arr.shape)\n",
    "\n",
    "print(test_img.shape)\n",
    "print(test_wea.shape)\n",
    "\n",
    "print(model.predict([test_img, test_wea]))\n",
    "\n",
    "y_pred = np.squeeze(np.round(model.predict([test_img, test_wea]).astype(np.int64)))\n",
    "\n",
    "print(test_val.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "print(np.round(test_val.astype(np.int64)))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 는 :  32.85438531604396\n",
      "R2SCORE 는 :  -0.01413230024161849\n"
     ]
    }
   ],
   "source": [
    "RMSE = mean_squared_error(test_val.astype(np.int64), y_pred)**0.5\n",
    "R2SCORE = r2_score(test_val.astype(np.int64), y_pred)\n",
    "\n",
    "print(\"RMSE 는 : \" , RMSE)\n",
    "print(\"R2SCORE 는 : \", R2SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(70, 50, 'R-squared = -0.01')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_val=np.squeeze(test_val.astype(np.int64))\n",
    "\n",
    "plt.scatter(test_val,y_pred)\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "\n",
    "plt.plot(np.unique(test_val), np.poly1d(np.polyfit(test_val, y_pred, 1))(np.unique(test_val)))\n",
    "\n",
    "plt.text(70, 50, 'R-squared = %0.2f' % R2SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52, 55, 55, ...,  3,  4,  4], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(test_val.astype(np.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 49, 49, ...,  8,  7,  6], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
